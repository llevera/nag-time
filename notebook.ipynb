{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b755fd4",
   "metadata": {},
   "source": [
    "# Creating a Blank Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa375271-2bc2-480a-83cc-69e063933b1b",
   "metadata": {
    "gather": {
     "logged": 1761359762988
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "✓ Imports completed\n",
      "✓ Configuration set - Device: cuda, Dtype: torch.bfloat16\n",
      "✓ Available models: ['base', 'dmd', 'turbo', 'lightning', 'lcm', 'hyper', 'pcm', 'tcd', 'flash']\n",
      "\n",
      "✓ Pipeline loader functions ready\n"
     ]
    }
   ],
   "source": [
    "# SDXL Model Pipeline Setup\n",
    "# Supports 9 distillation models with memory-efficient sequential loading\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import (\n",
    "    UNet2DConditionModel,\n",
    "    StableDiffusionXLPipeline,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    DDIMScheduler,\n",
    "    LCMScheduler,\n",
    "    TCDScheduler,\n",
    ")\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"✓ Imports completed\")\n",
    "\n",
    "# ---------- Configuration ----------\n",
    "device = \"cuda\"\n",
    "weights_dtype = torch.bfloat16\n",
    "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "model_configs = {\n",
    "    'base': {'steps': 100, 'recommended_cfg': 5.0},\n",
    "    'dmd': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'turbo': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'lightning': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'lcm': {'steps': 4, 'recommended_cfg': 1.0},\n",
    "    'hyper': {'steps': 8, 'recommended_cfg': 5.0},\n",
    "    'pcm': {'steps': 4, 'recommended_cfg': 2.0},\n",
    "    'tcd': {'steps': 4, 'recommended_cfg': 3.0},\n",
    "    'flash': {'steps': 4, 'recommended_cfg': 2.0}\n",
    "}\n",
    "\n",
    "print(f\"✓ Configuration set - Device: {device}, Dtype: {weights_dtype}\")\n",
    "print(f\"✓ Available models: {list(model_configs.keys())}\")\n",
    "\n",
    "# ---------- Model Loading Functions -------\n",
    "\n",
    "def load_model(distillation_type=None, weights_dtype=torch.float16, device='cuda'):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      'base'/'None': (pipe, base_unet, base_scheduler)\n",
    "      others:       (pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler)\n",
    "    \"\"\"\n",
    "    kind = ('base' if distillation_type in (None, 'base') else distillation_type).lower()\n",
    "    print(f\"Loading {kind.upper()} model...\")\n",
    "\n",
    "    # ---- base (always build this once for config/safety) ----\n",
    "    base_unet = UNet2DConditionModel.from_pretrained(\n",
    "        basemodel_id, subfolder=\"unet\", torch_dtype=weights_dtype\n",
    "    ).to(device)\n",
    "\n",
    "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        basemodel_id,\n",
    "        unet=base_unet,\n",
    "        torch_dtype=weights_dtype,\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    base_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.scheduler = base_scheduler\n",
    "    pipe.to(device=device, dtype=weights_dtype)\n",
    "\n",
    "    if kind == 'base':\n",
    "        return pipe, base_unet, base_scheduler\n",
    "\n",
    "    # fresh UNet matching base config (required for state_dict load)\n",
    "    distilled_unet = UNet2DConditionModel.from_config(pipe.unet.config).to(device, dtype=weights_dtype)\n",
    "\n",
    "    if kind == 'dmd':\n",
    "        repo_name, ckpt_name = \"tianweiy/DMD2\", \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
    "        state = torch.load(hf_hub_download(repo_name, ckpt_name), map_location='cpu')\n",
    "        distilled_unet.load_state_dict(state if isinstance(state, dict) else state['state_dict'])\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'lightning':\n",
    "        repo, ckpt = \"ByteDance/SDXL-Lightning\", \"sdxl_lightning_4step_unet.safetensors\"\n",
    "        state = load_file(hf_hub_download(repo, ckpt))\n",
    "        distilled_unet.load_state_dict(state, strict=True)\n",
    "        distilled_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'turbo':\n",
    "        # turbo ships a full UNet; pull that directly\n",
    "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"stabilityai/sdxl-turbo\", subfolder=\"unet\", torch_dtype=weights_dtype, variant=\"fp16\"\n",
    "        ).to(device)\n",
    "        distilled_scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'lcm':\n",
    "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"latent-consistency/lcm-sdxl\", torch_dtype=weights_dtype\n",
    "        ).to(device)\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'hyper':\n",
    "        from diffusers import DiffusionPipeline\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"ByteDance/Hyper-SD\",\n",
    "                               weight_name=\"Hyper-SDXL-8steps-CFG-lora.safetensors\",\n",
    "                               adapter_name=\"hyper-sdxl-8step\")\n",
    "        pipe.set_adapters([\"hyper-sdxl-8step\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'pcm':\n",
    "        from diffusers import DiffusionPipeline\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"wangfuyun/PCM_Weights\",\n",
    "                               weight_name=\"pcm_sdxl_smallcfg_4step_converted.safetensors\",\n",
    "                               subfolder=\"sdxl\",\n",
    "                               adapter_name=\"pcm-lora\")\n",
    "        pipe.set_adapters([\"pcm-lora\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'tcd':\n",
    "        from diffusers import DiffusionPipeline\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"h1t/TCD-SDXL-LoRA\", adapter_name=\"tcd-lora\")\n",
    "        pipe.set_adapters([\"tcd-lora\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'flash':\n",
    "        from diffusers import DiffusionPipeline\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"jasperai/flash-sdxl\",\n",
    "                               weight_name=\"pytorch_lora_weights.safetensors\",\n",
    "                               adapter_name=\"flash-sdxl\")\n",
    "        pipe.set_adapters([\"flash-sdxl\"], adapter_weights=[1.0])\n",
    "        pipe.fuse_lora()\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distillation type: '{distillation_type}'. \"\n",
    "                         f\"Available: {', '.join(sorted(model_configs.keys()))}\")\n",
    "\n",
    "    # IMPORTANT: actually use the distilled UNet\n",
    "    if hasattr(pipe, \"unet\") and distilled_unet is not pipe.unet:\n",
    "        pipe.unet = distilled_unet\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.to(device=device, dtype=weights_dtype)\n",
    "    return pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler\n",
    "\n",
    "\n",
    "def load_pipe(distillation_type='base', weights_dtype=torch.float16, device='cuda'):\n",
    "    \"\"\"\n",
    "    Returns a ready-to-sample pipeline with the correct UNet and scheduler.\n",
    "    \"\"\"\n",
    "    pipe_result = load_model(distillation_type, weights_dtype, device)\n",
    "    # result already sets the right scheduler/UNet when not 'base'\n",
    "    pipe = pipe_result[0]\n",
    "    print(f\"✓ {('base' if distillation_type in (None, 'base') else distillation_type).upper()} pipeline ready\")\n",
    "    return pipe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27107cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "nag-venv"
  },
  "kernelspec": {
   "display_name": "NAG Virtual Environment",
   "language": "python",
   "name": "nag-venv"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
