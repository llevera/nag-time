{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ef94728",
      "metadata": {},
      "source": [
        "# SDXL Model Pipeline Setup - Lightning Fix Applied\n",
        "Supports 9 distillation models with proper scheduler configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02129d5a",
      "metadata": {
        "gather": {
          "logged": 1761414008640
        }
      },
      "outputs": [],
      "source": [
        "# Imports and Configuration\n",
        "import sys\n",
        "import torch\n",
        "from typing import Union, List, Optional, Dict, Any, Tuple, Callable, Type\n",
        "from PIL import Image\n",
        "from diffusers import (\n",
        "    UNet2DConditionModel,\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    DDIMScheduler,\n",
        "    LCMScheduler,\n",
        "    TCDScheduler,\n",
        "    DiffusionPipeline,\n",
        ")\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "print(\"✓ Imports completed\")\n",
        "\n",
        "# ---------- Configuration ----------\n",
        "device = \"cuda\"\n",
        "weights_dtype = torch.bfloat16\n",
        "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "\n",
        "\n",
        "print(f\"✓ Configuration set - Device: {device}, Dtype: {weights_dtype}\")\n",
        "#print(f\"✓ Available models: {list(model_configs.keys())}\")\n",
        "\n",
        "\n",
        "def load_model(pipeline_cls: Type[DiffusionPipeline], distillation_type=None, weights_dtype=torch.float16, device='cuda'):\n",
        "    \"\"\"\n",
        "    Load SDXL models with specified distillation type.\n",
        "    \n",
        "    Returns:\n",
        "      'base'/'None': (pipe, base_unet, base_scheduler)\n",
        "      others:       (pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler)\n",
        "    \"\"\"\n",
        "    kind = ('base' if distillation_type in (None, 'base') else distillation_type).lower()\n",
        "    print(f\"Loading {kind.upper()} model...\")\n",
        "\n",
        "    # ---- base (always build this once for config/safety) ----\n",
        "    base_unet = UNet2DConditionModel.from_pretrained(\n",
        "        basemodel_id, subfolder=\"unet\", torch_dtype=weights_dtype\n",
        "    ).to(device)\n",
        "\n",
        "    pipe = pipeline_cls.from_pretrained(\n",
        "        basemodel_id,\n",
        "        unet=base_unet,\n",
        "        torch_dtype=weights_dtype,\n",
        "        use_safetensors=True,\n",
        "    )\n",
        "    base_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "    pipe.scheduler = base_scheduler\n",
        "    pipe.to(device=device, dtype=weights_dtype)\n",
        "\n",
        "    if kind == 'base':\n",
        "        return pipe, base_unet, base_scheduler\n",
        "\n",
        "    # fresh UNet matching base config (required for state_dict load)\n",
        "    distilled_unet = UNet2DConditionModel.from_config(pipe.unet.config).to(device, dtype=weights_dtype)\n",
        "\n",
        "    if kind == 'dmd':\n",
        "        repo_name, ckpt_name = \"tianweiy/DMD2\", \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "        state = torch.load(hf_hub_download(repo_name, ckpt_name), map_location='cpu')\n",
        "        distilled_unet.load_state_dict(state if isinstance(state, dict) else state['state_dict'])\n",
        "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    elif kind == 'lightning':\n",
        "        repo, ckpt = \"ByteDance/SDXL-Lightning\", \"sdxl_lightning_4step_unet.safetensors\"\n",
        "        state = load_file(hf_hub_download(repo, ckpt))\n",
        "        distilled_unet.load_state_dict(state, strict=True)\n",
        "        # FIX: Use EulerDiscreteScheduler with trailing timesteps for both schedulers\n",
        "        distilled_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "        base_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "\n",
        "    elif kind == 'turbo':\n",
        "        # turbo ships a full UNet; pull that directly\n",
        "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
        "            \"stabilityai/sdxl-turbo\", subfolder=\"unet\", torch_dtype=weights_dtype, variant=\"fp16\"\n",
        "        ).to(device)\n",
        "        distilled_scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "\n",
        "    elif kind == 'lcm':\n",
        "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
        "            \"latent-consistency/lcm-sdxl\", torch_dtype=weights_dtype\n",
        "        ).to(device)\n",
        "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    elif kind == 'hyper':\n",
        "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
        "        pipe.load_lora_weights(\"ByteDance/Hyper-SD\",\n",
        "                               weight_name=\"Hyper-SDXL-8steps-CFG-lora.safetensors\",\n",
        "                               adapter_name=\"hyper-sdxl-8step\")\n",
        "        pipe.set_adapters([\"hyper-sdxl-8step\"], adapter_weights=[1.0])\n",
        "        distilled_unet = pipe.unet\n",
        "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    elif kind == 'pcm':\n",
        "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
        "        pipe.load_lora_weights(\"wangfuyun/PCM_Weights\",\n",
        "                               weight_name=\"pcm_sdxl_smallcfg_4step_converted.safetensors\",\n",
        "                               subfolder=\"sdxl\",\n",
        "                               adapter_name=\"pcm-lora\")\n",
        "        pipe.set_adapters([\"pcm-lora\"], adapter_weights=[1.0])\n",
        "        distilled_unet = pipe.unet\n",
        "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "\n",
        "    elif kind == 'tcd':\n",
        "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
        "        pipe.load_lora_weights(\"h1t/TCD-SDXL-LoRA\", adapter_name=\"tcd-lora\")\n",
        "        pipe.set_adapters([\"tcd-lora\"], adapter_weights=[1.0])\n",
        "        distilled_unet = pipe.unet\n",
        "        distilled_scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    elif kind == 'flash':\n",
        "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
        "        pipe.load_lora_weights(\"jasperai/flash-sdxl\",\n",
        "                               weight_name=\"pytorch_lora_weights.safetensors\",\n",
        "                               adapter_name=\"flash-sdxl\")\n",
        "        pipe.set_adapters([\"flash-sdxl\"], adapter_weights=[1.0])\n",
        "        pipe.fuse_lora()\n",
        "        distilled_unet = pipe.unet\n",
        "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown distillation type: '{distillation_type}'. \"\n",
        "                         f\"Available: {', '.join(sorted(model_configs.keys()))}\")\n",
        "\n",
        "    # IMPORTANT: actually use the distilled UNet\n",
        "    if hasattr(pipe, \"unet\") and distilled_unet is not pipe.unet:\n",
        "        pipe.unet = distilled_unet\n",
        "    pipe.scheduler = distilled_scheduler\n",
        "    pipe.to(device=device, dtype=weights_dtype)\n",
        "    return pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler\n",
        "\n",
        "\n",
        "def load_pipe(pipeline_cls: Type[DiffusionPipeline], distillation_type='base'):\n",
        "    \"\"\"\n",
        "    Returns a ready-to-sample pipeline with the correct UNet and scheduler.\n",
        "    \"\"\"\n",
        "    pipe_result = load_model(pipeline_cls, distillation_type, weights_dtype, device)\n",
        "    # result already sets the right scheduler/UNet when not 'base'\n",
        "    pipe = pipe_result[0]\n",
        "    print(f\"✓ {('base' if distillation_type in (None, 'base') else distillation_type).upper()} pipeline ready\")\n",
        "    return pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c58c56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# NAG Attention Processor - from attention_nag.py\n",
        "from typing import Optional\n",
        "\n",
        "class NAGAttnProcessor2_0:\n",
        "    \"\"\"\n",
        "    Normalized Attention Guidance (NAG) attention processor using PyTorch 2.0's\n",
        "    scaled_dot_product_attention for efficient computation.\n",
        "    \"\"\"\n",
        "    def __init__(self, nag_scale: float = 1.0, nag_tau: float = 2.5, nag_alpha: float = 0.5):\n",
        "        if not hasattr(F, \"scaled_dot_product_attention\"):\n",
        "            raise ImportError(\"AttnProcessor2_0 requires PyTorch 2.0, to use it, please upgrade PyTorch to 2.0.\")\n",
        "        self.nag_scale = nag_scale\n",
        "        self.nag_tau = nag_tau\n",
        "        self.nag_alpha = nag_alpha\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        attn,\n",
        "        hidden_states: torch.Tensor,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        temb: Optional[torch.Tensor] = None,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ) -> torch.Tensor:\n",
        "        if len(args) > 0 or kwargs.get(\"scale\", None) is not None:\n",
        "            deprecation_message = \"The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\"\n",
        "            deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
        "\n",
        "        residual = hidden_states\n",
        "        if attn.spatial_norm is not None:\n",
        "            hidden_states = attn.spatial_norm(hidden_states, temb)\n",
        "\n",
        "        input_ndim = hidden_states.ndim\n",
        "\n",
        "        if input_ndim == 4:\n",
        "            batch_size, channel, height, width = hidden_states.shape\n",
        "            hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)\n",
        "\n",
        "        batch_size, sequence_length, _ = (\n",
        "            hidden_states.shape if encoder_hidden_states is None else encoder_hidden_states.shape\n",
        "        )\n",
        "\n",
        "        apply_guidance = self.nag_scale > 1 and encoder_hidden_states is not None\n",
        "        if apply_guidance:\n",
        "            origin_batch_size = batch_size - len(hidden_states)\n",
        "            assert batch_size / origin_batch_size in [2, 3, 4]\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, batch_size)\n",
        "            attention_mask = attention_mask.view(batch_size, attn.heads, -1, attention_mask.shape[-1])\n",
        "\n",
        "        if attn.group_norm is not None:\n",
        "            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "        query = attn.to_q(hidden_states)\n",
        "\n",
        "        if encoder_hidden_states is None:\n",
        "            encoder_hidden_states = hidden_states\n",
        "        elif attn.norm_cross:\n",
        "            encoder_hidden_states = attn.norm_encoder_hidden_states(encoder_hidden_states)\n",
        "\n",
        "        key = attn.to_k(encoder_hidden_states)\n",
        "        value = attn.to_v(encoder_hidden_states)\n",
        "\n",
        "        inner_dim = key.shape[-1]\n",
        "        head_dim = inner_dim // attn.heads\n",
        "\n",
        "        if apply_guidance:\n",
        "            if batch_size == 2 * origin_batch_size:\n",
        "                query = query.tile(2, 1, 1)\n",
        "            else:\n",
        "                query = torch.cat((query, query[origin_batch_size:2 * origin_batch_size]), dim=0)\n",
        "        query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "        value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        if attn.norm_q is not None:\n",
        "            query = attn.norm_q(query)\n",
        "        if attn.norm_k is not None:\n",
        "            key = attn.norm_k(key)\n",
        "\n",
        "        hidden_states = F.scaled_dot_product_attention(\n",
        "            query, key, value, attn_mask=attention_mask, dropout_p=0.0, is_causal=False\n",
        "        )\n",
        "\n",
        "        hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, attn.heads * head_dim)\n",
        "        hidden_states = hidden_states.to(query.dtype)\n",
        "\n",
        "        if apply_guidance:\n",
        "            hidden_states_negative = hidden_states[-origin_batch_size:]\n",
        "            if batch_size == 2 * origin_batch_size:\n",
        "                hidden_states_positive = hidden_states[:origin_batch_size]\n",
        "            else:\n",
        "                hidden_states_positive = hidden_states[origin_batch_size:2 * origin_batch_size]\n",
        "            hidden_states_guidance = hidden_states_positive * self.nag_scale - hidden_states_negative * (self.nag_scale - 1)\n",
        "            norm_positive = torch.norm(hidden_states_positive, p=1, dim=-1, keepdim=True).expand(*hidden_states_positive.shape)\n",
        "            norm_guidance = torch.norm(hidden_states_guidance, p=1, dim=-1, keepdim=True).expand(*hidden_states_guidance.shape)\n",
        "\n",
        "            scale = norm_guidance / norm_positive\n",
        "            hidden_states_guidance = hidden_states_guidance * torch.minimum(scale, scale.new_ones(1) * self.nag_tau) / scale\n",
        "\n",
        "            hidden_states_guidance = hidden_states_guidance * self.nag_alpha + hidden_states_positive * (1 - self.nag_alpha)\n",
        "\n",
        "            if batch_size == 2 * origin_batch_size:\n",
        "                hidden_states = hidden_states_guidance\n",
        "            elif batch_size == 3 * origin_batch_size:\n",
        "                hidden_states = torch.cat((hidden_states[:origin_batch_size], hidden_states_guidance), dim=0)\n",
        "            elif batch_size == 4 * origin_batch_size:\n",
        "                hidden_states = torch.cat((hidden_states[:origin_batch_size], hidden_states_guidance, hidden_states[2 * origin_batch_size:3 * origin_batch_size]), dim=0)\n",
        "\n",
        "        hidden_states = attn.to_out[0](hidden_states)\n",
        "        hidden_states = attn.to_out[1](hidden_states)\n",
        "\n",
        "        if input_ndim == 4:\n",
        "            hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)\n",
        "\n",
        "        if attn.residual_connection:\n",
        "            hidden_states = hidden_states + residual\n",
        "\n",
        "        hidden_states = hidden_states / attn.rescale_output_factor\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "print(\"✓ NAGAttnProcessor2_0 loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c35480c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# NAG Pipeline with Timing - from pipeline_sdxl_impactful_nag.py\n",
        "import math\n",
        "from diffusers.callbacks import MultiPipelineCallbacks, PipelineCallback\n",
        "from diffusers.image_processor import PipelineImageInput\n",
        "from diffusers.utils import deprecate, is_torch_xla_available\n",
        "from diffusers.pipelines.stable_diffusion_xl.pipeline_output import StableDiffusionXLPipelineOutput\n",
        "from diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl import (\n",
        "    retrieve_timesteps,\n",
        "    rescale_noise_cfg,\n",
        ")\n",
        "from typing import Union, List, Optional, Dict, Any, Tuple, Callable\n",
        "\n",
        "if is_torch_xla_available():\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    XLA_AVAILABLE = True\n",
        "else:\n",
        "    XLA_AVAILABLE = False\n",
        "\n",
        "# Now the timing-aware variant\n",
        "class NAGTimeStableDiffusionXLPipeline(StableDiffusionXLPipeline):\n",
        "\n",
        "    \"\"\"Base NAG pipeline that extends StableDiffusionXLPipeline\"\"\"\n",
        "    \n",
        "    @property\n",
        "    def do_normalized_attention_guidance(self):\n",
        "        return self._nag_scale > 1\n",
        "\n",
        "    def _set_nag_attn_processor(self, nag_scale, nag_tau=2.5, nag_alpha=0.5):\n",
        "        if self.do_normalized_attention_guidance:\n",
        "            attn_procs = {}\n",
        "            for name, origin_attn_processor in self.unet.attn_processors.items():\n",
        "                if \"attn2\" in name:\n",
        "                    attn_procs[name] = NAGAttnProcessor2_0(nag_scale=nag_scale, nag_tau=nag_tau, nag_alpha=nag_alpha)\n",
        "                else:\n",
        "                    attn_procs[name] = origin_attn_processor\n",
        "            self.unet.set_attn_processor(attn_procs)\n",
        "\n",
        "    \"\"\"\n",
        "    NAG with timing from 'Impact of Negative Prompts':\n",
        "    - Delay enabling NAG until nag_start fraction of the trajectory\n",
        "    - Optional linear ramp of nag_scale for nag_ramp_steps after start\n",
        "    - Keep existing nag_end behaviour\n",
        "\n",
        "    Backwards-compatible cool-down (time-based):\n",
        "    - Optional post-NAG cool-down that temporarily reduces CFG by a fraction.\n",
        "    - Disabled by default (nag_cooldown=0.0) to preserve existing behaviour.\n",
        "    \"\"\"\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(\n",
        "        self,\n",
        "        prompt: Union[str, List[str]] = None,\n",
        "        prompt_2: Optional[Union[str, List[str]]] = None,\n",
        "        height: Optional[int] = None,\n",
        "        width: Optional[int] = None,\n",
        "        num_inference_steps: int = 50,\n",
        "        timesteps: List[int] = None,\n",
        "        sigmas: List[float] = None,\n",
        "        denoising_end: Optional[float] = None,\n",
        "        guidance_scale: float = 5.0,\n",
        "        negative_prompt: Optional[Union[str, List[str]]] = None,\n",
        "        negative_prompt_2: Optional[Union[str, List[str]]] = None,\n",
        "        num_images_per_prompt: Optional[int] = 1,\n",
        "        eta: float = 0.0,\n",
        "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
        "        latents: Optional[torch.Tensor] = None,\n",
        "        prompt_embeds: Optional[torch.Tensor] = None,\n",
        "        negative_prompt_embeds: Optional[torch.Tensor] = None,\n",
        "        pooled_prompt_embeds: Optional[torch.Tensor] = None,\n",
        "        negative_pooled_prompt_embeds: Optional[torch.Tensor] = None,\n",
        "        ip_adapter_image: Optional[PipelineImageInput] = None,\n",
        "        ip_adapter_image_embeds: Optional[List[torch.Tensor]] = None,\n",
        "        output_type: Optional[str] = \"pil\",\n",
        "        return_dict: bool = True,\n",
        "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
        "        guidance_rescale: float = 0.0,\n",
        "        original_size: Optional[Tuple[int, int]] = None,\n",
        "        crops_coords_top_left: Tuple[int, int] = (0, 0),\n",
        "        target_size: Optional[Tuple[int, int]] = None,\n",
        "        negative_original_size: Optional[Tuple[int, int]] = None,\n",
        "        negative_crops_coords_top_left: Tuple[int, int] = (0, 0),\n",
        "        negative_target_size: Optional[Tuple[int, int]] = None,\n",
        "        clip_skip: Optional[int] = None,\n",
        "        callback_on_step_end: Optional[\n",
        "            Union[Callable[[int, int, Dict], None], PipelineCallback, MultiPipelineCallbacks]\n",
        "        ] = None,\n",
        "        callback_on_step_end_tensor_inputs: List[str] = [\"latents\"],\n",
        "\n",
        "        # NAG controls\n",
        "        nag_scale: float = 1.0,\n",
        "        nag_tau: float = 2.5,\n",
        "        nag_alpha: float = 0.5,\n",
        "        nag_negative_prompt: str = None,\n",
        "        nag_negative_prompt_embeds: Optional[torch.Tensor] = None,\n",
        "        nag_end: float = 1.0,\n",
        "\n",
        "        # Timing knobs from Impact of Negative Prompts\n",
        "        nag_start: float = 0.2,          # start NAG after 20% of the trajectory\n",
        "        nag_ramp_steps: int = 0,         # optional soft-start; 0 disables ramp\n",
        "\n",
        "        # NEW: time-based cool-down (fully backward compatible when 0.0)\n",
        "        nag_cooldown: float = 0.0,          # fraction after nag_end to apply cool-down (0.0 = disabled)\n",
        "        nag_cooldown_cfg_drop: float = 0.2, # relative CFG reduction during cool-down (e.g., 0.2 = -20%)\n",
        "\n",
        "        **kwargs,\n",
        "    ):\n",
        "        callback = kwargs.pop(\"callback\", None)\n",
        "        callback_steps = kwargs.pop(\"callback_steps\", None)\n",
        "\n",
        "        if callback is not None:\n",
        "            deprecate(\n",
        "                \"callback\",\n",
        "                \"1.0.0\",\n",
        "                \"Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`\",\n",
        "            )\n",
        "        if callback_steps is not None:\n",
        "            deprecate(\n",
        "                \"callback_steps\",\n",
        "                \"1.0.0\",\n",
        "                \"Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`\",\n",
        "            )\n",
        "\n",
        "        if isinstance(callback_on_step_end, (PipelineCallback, MultiPipelineCallbacks)):\n",
        "            callback_on_step_end_tensor_inputs = callback_on_step_end.tensor_inputs\n",
        "\n",
        "        # 0. Defaults\n",
        "        height = height or self.default_sample_size * self.vae_scale_factor\n",
        "        width = width or self.default_sample_size * self.vae_scale_factor\n",
        "        original_size = original_size or (height, width)\n",
        "        target_size = target_size or (height, width)\n",
        "\n",
        "        # 1. Check inputs\n",
        "        self.check_inputs(\n",
        "            prompt,\n",
        "            prompt_2,\n",
        "            height,\n",
        "            width,\n",
        "            callback_steps,\n",
        "            negative_prompt,\n",
        "            negative_prompt_2,\n",
        "            prompt_embeds,\n",
        "            negative_prompt_embeds,\n",
        "            pooled_prompt_embeds,\n",
        "            negative_pooled_prompt_embeds,\n",
        "            ip_adapter_image,\n",
        "            ip_adapter_image_embeds,\n",
        "            callback_on_step_end_tensor_inputs,\n",
        "        )\n",
        "\n",
        "        self._guidance_scale = guidance_scale\n",
        "        self._guidance_rescale = guidance_rescale\n",
        "        self._clip_skip = clip_skip\n",
        "        self._cross_attention_kwargs = cross_attention_kwargs\n",
        "        self._denoising_end = denoising_end\n",
        "        self._interrupt = False\n",
        "        self._nag_scale = nag_scale\n",
        "\n",
        "        # 2. Batch size\n",
        "        if prompt is not None and isinstance(prompt, str):\n",
        "            batch_size = 1\n",
        "        elif prompt is not None and isinstance(prompt, list):\n",
        "            batch_size = len(prompt)\n",
        "        else:\n",
        "            batch_size = prompt_embeds.shape[0]\n",
        "\n",
        "        device = self._execution_device\n",
        "\n",
        "        # 3. Encode prompts\n",
        "        lora_scale = self.cross_attention_kwargs.get(\"scale\", None) if self.cross_attention_kwargs is not None else None\n",
        "\n",
        "        (\n",
        "            prompt_embeds,\n",
        "            negative_prompt_embeds,\n",
        "            pooled_prompt_embeds,\n",
        "            negative_pooled_prompt_embeds,\n",
        "        ) = self.encode_prompt(\n",
        "            prompt=prompt,\n",
        "            prompt_2=prompt_2,\n",
        "            device=device,\n",
        "            num_images_per_prompt=num_images_per_prompt,\n",
        "            do_classifier_free_guidance=self.do_classifier_free_guidance or self.do_normalized_attention_guidance,\n",
        "            negative_prompt=negative_prompt,\n",
        "            negative_prompt_2=negative_prompt_2,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            pooled_prompt_embeds=pooled_prompt_embeds,\n",
        "            negative_pooled_prompt_embeds=negative_pooled_prompt_embeds,\n",
        "            lora_scale=lora_scale,\n",
        "            clip_skip=self.clip_skip,\n",
        "        )\n",
        "\n",
        "        # Prepare NAG negative embeddings (but DO NOT append yet; we enable later)\n",
        "        if self.do_normalized_attention_guidance:\n",
        "            if nag_negative_prompt_embeds is None:\n",
        "                if nag_negative_prompt is None:\n",
        "                    if negative_prompt is not None:\n",
        "                        if self.do_classifier_free_guidance:\n",
        "                            nag_negative_prompt_embeds = negative_prompt_embeds\n",
        "                        else:\n",
        "                            nag_negative_prompt = negative_prompt\n",
        "                    else:\n",
        "                        nag_negative_prompt = \"\"\n",
        "                if nag_negative_prompt is not None and nag_negative_prompt_embeds is None:\n",
        "                    nag_negative_prompt_embeds = self.encode_prompt(\n",
        "                        prompt=nag_negative_prompt,\n",
        "                        device=device,\n",
        "                        num_images_per_prompt=num_images_per_prompt,\n",
        "                        do_classifier_free_guidance=False,\n",
        "                        lora_scale=lora_scale,\n",
        "                        clip_skip=self.clip_skip,\n",
        "                    )[0]\n",
        "\n",
        "        # 4. Timesteps\n",
        "        timesteps, num_inference_steps = retrieve_timesteps(\n",
        "            self.scheduler, num_inference_steps, device, timesteps, sigmas\n",
        "        )\n",
        "\n",
        "        # 5. Latents\n",
        "        num_channels_latents = self.unet.config.in_channels\n",
        "        latents = self.prepare_latents(\n",
        "            batch_size * num_images_per_prompt,\n",
        "            num_channels_latents,\n",
        "            height,\n",
        "            width,\n",
        "            prompt_embeds.dtype,\n",
        "            device,\n",
        "            generator,\n",
        "            latents,\n",
        "        )\n",
        "\n",
        "        # 6. Extra step kwargs\n",
        "        extra_step_kwargs = self.prepare_extra_step_kwargs(generator, eta)\n",
        "\n",
        "        # 7. Added time ids & embeddings\n",
        "        add_text_embeds = pooled_prompt_embeds\n",
        "        if self.text_encoder_2 is None:\n",
        "            text_encoder_projection_dim = int(pooled_prompt_embeds.shape[-1])\n",
        "        else:\n",
        "            text_encoder_projection_dim = self.text_encoder_2.config.projection_dim\n",
        "\n",
        "        add_time_ids = self._get_add_time_ids(\n",
        "            original_size,\n",
        "            crops_coords_top_left,\n",
        "            target_size,\n",
        "            dtype=prompt_embeds.dtype,\n",
        "            text_encoder_projection_dim=text_encoder_projection_dim,\n",
        "        )\n",
        "        if negative_original_size is not None and negative_target_size is not None:\n",
        "            negative_add_time_ids = self._get_add_time_ids(\n",
        "                negative_original_size,\n",
        "                negative_crops_coords_top_left,\n",
        "                negative_target_size,\n",
        "                dtype=prompt_embeds.dtype,\n",
        "                text_encoder_projection_dim=text_encoder_projection_dim,\n",
        "            )\n",
        "        else:\n",
        "            negative_add_time_ids = add_time_ids\n",
        "\n",
        "        if self.do_classifier_free_guidance:\n",
        "            prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds], dim=0)\n",
        "            add_text_embeds = torch.cat([negative_pooled_prompt_embeds, add_text_embeds], dim=0)\n",
        "            add_time_ids = torch.cat([negative_add_time_ids, add_time_ids], dim=0)\n",
        "\n",
        "        # NOTE: Delayed NAG — do NOT append nag_negative_prompt_embeds yet.\n",
        "\n",
        "        prompt_embeds = prompt_embeds.to(device)\n",
        "        add_text_embeds = add_text_embeds.to(device)\n",
        "        add_time_ids = add_time_ids.to(device).repeat(batch_size * num_images_per_prompt, 1)\n",
        "\n",
        "        if ip_adapter_image is not None or ip_adapter_image_embeds is not None:\n",
        "            image_embeds = self.prepare_ip_adapter_image_embeds(\n",
        "                ip_adapter_image,\n",
        "                ip_adapter_image_embeds,\n",
        "                device,\n",
        "                batch_size * num_images_per_prompt,\n",
        "                self.do_classifier_free_guidance,\n",
        "            )\n",
        "\n",
        "        # 8. Denoising setup\n",
        "        num_warmup_steps = max(len(timesteps) - num_inference_steps * self.scheduler.order, 0)\n",
        "\n",
        "        # 8.1 denoising_end\n",
        "        if (\n",
        "            self.denoising_end is not None\n",
        "            and isinstance(self.denoising_end, float)\n",
        "            and 0 < self.denoising_end < 1\n",
        "        ):\n",
        "            discrete_timestep_cutoff = int(\n",
        "                round(\n",
        "                    self.scheduler.config.num_train_timesteps\n",
        "                    - (self.denoising_end * self.scheduler.config.num_train_timesteps)\n",
        "                )\n",
        "            )\n",
        "            num_inference_steps = len([ts for ts in timesteps if ts >= discrete_timestep_cutoff])\n",
        "            timesteps = timesteps[:num_inference_steps]\n",
        "\n",
        "        # 9. Guidance scale embedding (base / default)\n",
        "        # For full backward-compatibility, we precompute the \"base\" embedding as before.\n",
        "        base_timestep_cond = None\n",
        "        if self.unet.config.time_cond_proj_dim is not None:\n",
        "            base_gs_tensor = torch.tensor(self.guidance_scale - 1).repeat(batch_size * num_images_per_prompt)\n",
        "            base_timestep_cond = self.get_guidance_scale_embedding(\n",
        "                base_gs_tensor, embedding_dim=self.unet.config.time_cond_proj_dim\n",
        "            ).to(device=device, dtype=latents.dtype)\n",
        "\n",
        "        # ---- NEW: timing state for NAG & cool-down ----\n",
        "        def _to_ddpm(frac: float) -> int:\n",
        "            # clamp to [0,1], map to DDPM 0..999, note timesteps are descending\n",
        "            frac = max(0.0, min(1.0, float(frac)))\n",
        "            return math.floor((1 - frac) * 999)\n",
        "\n",
        "        nag_start_t = _to_ddpm(nag_start)\n",
        "        nag_end_t = _to_ddpm(nag_end)\n",
        "\n",
        "        # Cool-down window [nag_end, nag_end + nag_cooldown] in fractional time, then map to DDPM t.\n",
        "        cooldown_active = float(nag_cooldown) > 0.0\n",
        "        if cooldown_active:\n",
        "            cooldown_end_frac = min(1.0, float(nag_end) + float(nag_cooldown))\n",
        "            cooldown_end_t = _to_ddpm(cooldown_end_frac)\n",
        "        else:\n",
        "            cooldown_end_t = None  # unused\n",
        "\n",
        "        origin_attn_procs = self.unet.attn_processors\n",
        "        attn_procs_applied = False\n",
        "        attn_procs_recovered = False\n",
        "        i_start = None  # loop index when NAG is enabled\n",
        "\n",
        "        self._num_timesteps = len(timesteps)\n",
        "        with self.progress_bar(total=num_inference_steps) as progress_bar:\n",
        "            for i, t in enumerate(timesteps):\n",
        "                if self.interrupt:\n",
        "                    continue\n",
        "\n",
        "                # Build latent input\n",
        "                latent_model_input = torch.cat([latents] * 2) if self.do_classifier_free_guidance else latents\n",
        "                latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "                # ---- Enable NAG once we reach nag_start ----\n",
        "                if (\n",
        "                    self.do_normalized_attention_guidance\n",
        "                    and not attn_procs_applied\n",
        "                    and t <= nag_start_t\n",
        "                ):\n",
        "                    # initial scale for ramp\n",
        "                    current_scale = 1.0 if nag_ramp_steps > 0 else nag_scale\n",
        "                    self._set_nag_attn_processor(current_scale, nag_tau, nag_alpha)\n",
        "\n",
        "                    # append the NAG negative branch now\n",
        "                    if nag_negative_prompt_embeds is not None:\n",
        "                        prompt_embeds = torch.cat([prompt_embeds, nag_negative_prompt_embeds], dim=0)\n",
        "\n",
        "                    attn_procs_applied = True\n",
        "                    i_start = i  # remember start index\n",
        "\n",
        "                # ---- Optionally ramp the nag_scale for a few steps after start ----\n",
        "                if (\n",
        "                    self.do_normalized_attention_guidance\n",
        "                    and attn_procs_applied\n",
        "                    and not attn_procs_recovered\n",
        "                    and nag_ramp_steps > 0\n",
        "                    and i_start is not None\n",
        "                ):\n",
        "                    steps_since_on = max(0, i - i_start)\n",
        "                    if steps_since_on <= nag_ramp_steps:\n",
        "                        ramped = 1.0 + (nag_scale - 1.0) * (steps_since_on / max(1, nag_ramp_steps))\n",
        "                        self._set_nag_attn_processor(ramped, nag_tau, nag_alpha)\n",
        "                    else:\n",
        "                        # ensure final scale is set once ramp completes\n",
        "                        if abs(self._nag_scale - nag_scale) > 1e-6:\n",
        "                            self._set_nag_attn_processor(nag_scale, nag_tau, nag_alpha)\n",
        "\n",
        "                # ---- Disable NAG when we pass nag_end ----\n",
        "                if (\n",
        "                    self.do_normalized_attention_guidance\n",
        "                    and attn_procs_applied\n",
        "                    and not attn_procs_recovered\n",
        "                    and t < nag_end_t\n",
        "                ):\n",
        "                    self.unet.set_attn_processor(origin_attn_procs)\n",
        "                    # drop the appended branch so shapes match again\n",
        "                    prompt_embeds = prompt_embeds[: len(latent_model_input)]\n",
        "                    attn_procs_recovered = True\n",
        "\n",
        "                # ---- Cool-down (time-based) effective CFG ----\n",
        "                if cooldown_active:\n",
        "                    # In DDPM indexing, smaller t means later in the trajectory.\n",
        "                    # We are \"in cool-down\" if we've gone *past* nag_end (t <= nag_end_t)\n",
        "                    # but not yet beyond the cool-down window end (t >= cooldown_end_t).\n",
        "                    in_cooldown = (t <= nag_end_t) and (t >= cooldown_end_t)\n",
        "                else:\n",
        "                    in_cooldown = False\n",
        "\n",
        "                if in_cooldown:\n",
        "                    current_guidance_scale = max(1.0, self.guidance_scale * (1.0 - float(nag_cooldown_cfg_drop)))\n",
        "                else:\n",
        "                    current_guidance_scale = self.guidance_scale\n",
        "\n",
        "                # Build timestep_cond:\n",
        "                # - If no cool-down (default), reuse base embedding (backwards-compatible).\n",
        "                # - If cool-down is active, rebuild embedding with the step's effective CFG.\n",
        "                if self.unet.config.time_cond_proj_dim is not None:\n",
        "                    if cooldown_active:\n",
        "                        gs_tensor = torch.tensor(current_guidance_scale - 1).repeat(batch_size * num_images_per_prompt)\n",
        "                        timestep_cond = self.get_guidance_scale_embedding(\n",
        "                            gs_tensor, embedding_dim=self.unet.config.time_cond_proj_dim\n",
        "                        ).to(device=device, dtype=latents.dtype)\n",
        "                    else:\n",
        "                        timestep_cond = base_timestep_cond\n",
        "                else:\n",
        "                    timestep_cond = None\n",
        "\n",
        "                # predict noise\n",
        "                added_cond_kwargs = {\"text_embeds\": add_text_embeds, \"time_ids\": add_time_ids}\n",
        "                if ip_adapter_image is not None or ip_adapter_image_embeds is not None:\n",
        "                    added_cond_kwargs[\"image_embeds\"] = image_embeds\n",
        "\n",
        "                noise_pred = self.unet(\n",
        "                    latent_model_input,\n",
        "                    t,\n",
        "                    encoder_hidden_states=prompt_embeds,\n",
        "                    timestep_cond=timestep_cond,\n",
        "                    cross_attention_kwargs=self.cross_attention_kwargs,\n",
        "                    added_cond_kwargs=added_cond_kwargs,\n",
        "                    return_dict=False,\n",
        "                )[0]\n",
        "\n",
        "                # CFG (use effective guidance for this step; identical to old behaviour when cool-down is off)\n",
        "                if self.do_classifier_free_guidance:\n",
        "                    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "                    noise_pred = noise_pred_uncond + current_guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "                if self.do_classifier_free_guidance and self.guidance_rescale > 0.0:\n",
        "                    noise_pred = rescale_noise_cfg(noise_pred, noise_pred_text, guidance_rescale=self.guidance_rescale)\n",
        "\n",
        "                # step scheduler\n",
        "                latents_dtype = latents.dtype\n",
        "                latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs, return_dict=False)[0]\n",
        "                if latents.dtype != latents_dtype and torch.backends.mps.is_available():\n",
        "                    latents = latents.to(latents_dtype)\n",
        "\n",
        "                # callbacks\n",
        "                if callback_on_step_end is not None:\n",
        "                    callback_kwargs = {}\n",
        "                    for k in callback_on_step_end_tensor_inputs:\n",
        "                        callback_kwargs[k] = locals()[k]\n",
        "                    callback_outputs = callback_on_step_end(self, i, t, callback_kwargs)\n",
        "\n",
        "                    latents = callback_outputs.pop(\"latents\", latents)\n",
        "                    prompt_embeds = callback_outputs.pop(\"prompt_embeds\", prompt_embeds)\n",
        "                    negative_prompt_embeds = callback_outputs.pop(\"negative_prompt_embeds\", negative_prompt_embeds)\n",
        "                    add_text_embeds = callback_outputs.pop(\"add_text_embeds\", add_text_embeds)\n",
        "                    negative_pooled_prompt_embeds = callback_outputs.pop(\n",
        "                        \"negative_pooled_prompt_embeds\", negative_pooled_prompt_embeds\n",
        "                    )\n",
        "                    add_time_ids = callback_outputs.pop(\"add_time_ids\", add_time_ids)\n",
        "\n",
        "                if i == len(timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % self.scheduler.order == 0):\n",
        "                    progress_bar.update()\n",
        "                    if callback is not None and i % callback_steps == 0:\n",
        "                        step_idx = i // getattr(self.scheduler, \"order\", 1)\n",
        "                        callback(step_idx, t, latents)\n",
        "\n",
        "                if XLA_AVAILABLE:\n",
        "                    xm.mark_step()\n",
        "\n",
        "        # decode\n",
        "        if output_type != \"latent\":\n",
        "            needs_upcasting = self.vae.dtype == torch.float16 and self.vae.config.force_upcast\n",
        "            if needs_upcasting:\n",
        "                self.upcast_vae()\n",
        "                latents = latents.to(next(iter(self.vae.post_quant_conv.parameters())).dtype)\n",
        "            elif latents.dtype != self.vae.dtype and torch.backends.mps.is_available():\n",
        "                self.vae = self.vae.to(latents.dtype)\n",
        "\n",
        "            has_latents_mean = hasattr(self.vae.config, \"latents_mean\") and self.vae.config.latents_mean is not None\n",
        "            has_latents_std = hasattr(self.vae.config, \"latents_std\") and self.vae.config.latents_std is not None\n",
        "            if has_latents_mean and has_latents_std:\n",
        "                latents_mean = torch.tensor(self.vae.config.latents_mean).view(1, 4, 1, 1).to(latents.device, latents.dtype)\n",
        "                latents_std = torch.tensor(self.vae.config.latents_std).view(1, 4, 1, 1).to(latents.device, latents.dtype)\n",
        "                latents = latents * latents_std / self.vae.config.scaling_factor + latents_mean\n",
        "            else:\n",
        "                latents = latents / self.vae.config.scaling_factor\n",
        "\n",
        "            image = self.vae.decode(latents, return_dict=False)[0]\n",
        "\n",
        "            if needs_upcasting:\n",
        "                self.vae.to(dtype=torch.float16)\n",
        "        else:\n",
        "            image = latents\n",
        "\n",
        "        if output_type != \"latent\":\n",
        "            if self.watermark is not None:\n",
        "                image = self.watermark.apply_watermark(image)\n",
        "            image = self.image_processor.postprocess(image, output_type=output_type)\n",
        "\n",
        "        # ensure processors are restored\n",
        "        if self.do_normalized_attention_guidance and not attn_procs_recovered:\n",
        "            self.unet.set_attn_processor(origin_attn_procs)\n",
        "\n",
        "        self.maybe_free_model_hooks()\n",
        "\n",
        "        if not return_dict:\n",
        "            return (image,)\n",
        "        return StableDiffusionXLPipelineOutput(images=image)\n",
        "\n",
        "print(\"✓ NAGTimeStableDiffusionXLPipeline loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b0adb1",
      "metadata": {},
      "source": [
        "## Test Across Select Models\n",
        "Run tests on multiple models with first 10 prompts and first seed, organized by model folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1774ad30",
      "metadata": {
        "gather": {
          "logged": 1761418568009
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0030_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd5cba2601eb462a8da8692d6c720af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0030_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb167f5521b04e0f8c7e38b3ba2b9e19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0030_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c000186685ea4ca2b83282b5fb2adc71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0030_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5441be852a54f91a277add3d42e0f14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0030_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0d6268ebd704a7984cf212c8c1df2b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0030_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "914bf7ab321e4a60ac96c4c558502962",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0030_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b90010e9a7a1408591b90b89e31c5020",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0030_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fd82930cd6845cfb5f975425ade4504",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0030_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  62%|██████▏   | 31/50 [04:08<02:34,  8.15s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b00c518f65c443caa03c611be89c2d48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0031_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61b29b12ac9a4b209ce1f28ba3e74727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0031_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca3573e92e0c4487b854ab77b5900dc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0031_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2ee4539ce6435bb5dbde33aead0a6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0031_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "290abb88ca254f72a6b2c82e33750807",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0031_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aa55997ed2a46ee87dd4d4167509a3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0031_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d106b90d7b064ba9abe2c837c4ef9d0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0031_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76aa3498422141969d87ae9e2c837497",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0031_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29e7c44bf57b4323a9983474f736461a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0031_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  64%|██████▍   | 32/50 [04:16<02:24,  8.02s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23b12a6f81a14e169f81b0c5077ea7a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0032_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbd35e667b3c49eb84254c5d79c2e937",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0032_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cf6c8a43f014d029f6e45c66cbcaf96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0032_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58ce9958799344359c1fa50cf0e47025",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0032_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54ce5f77c5de4f9c9c12cf027d5527d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0032_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23f744cfcefa402cbf7833ffdd69bafa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0032_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95929d46e5d2428da439ccf4865644c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0032_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08605c72807d434c8b953a9e0db4ae8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0032_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fdf93742173498a8b93a305e9207d22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0032_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  66%|██████▌   | 33/50 [04:24<02:17,  8.07s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b8578d901df47c58438c5b9db2415b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0033_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9670e579184e4e8fb643ef90e53b2a7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0033_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93b399b552994402b63ac2df32e966fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0033_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b35bbe4a8c8340b0b19b863deacff57a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0033_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa5b2f8149b045f3990cc11237f79f59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0033_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cff69e94d1f42f7a3513ac3178d5f7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0033_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa455550ce9140c687adb7808d4a867a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0033_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64af1a02167d490b8a88dd89b8b07578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0033_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80660ec79cad403b89ac46b108ff8cbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0033_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  68%|██████▊   | 34/50 [04:32<02:11,  8.21s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be6d84a675f04fe9af81eabf22d1ac75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0034_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caefac3c021c4113b91008754c633598",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0034_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d3facdc56b343e2bf153188987f5296",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0034_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbc655eeaf3c4287a6b386bca5008828",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0034_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3fbe8445f8747a9b1939ef2a7d58dea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0034_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a485c93245df44e19d26d5d54d639143",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0034_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "502a972f17674151af9cf2e8c45482be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0034_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eb3ebffaa434eccb956221df078e899",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0034_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "564d5d44591b467ab401bd6c0d64f61b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0034_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  70%|███████   | 35/50 [04:40<02:02,  8.17s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4de76daf6e9d420da7ac86d49cc43020",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0035_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cee626f9c5db4223bbbd3378cdee3898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0035_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1add3d8abfac4395bcc2b11584fcef36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0035_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9122f7b2f0b4f04a36143221096a172",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0035_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d125b1d5d63f45f3a3ab265e47f4ca77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0035_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8afc8f80a4404d789e7966ff7e0f99ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0035_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d27bdfebf733470583d562c5f4f1f412",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0035_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "584fa9d832a94754b8faad5c3de3d0bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0035_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9859c68ba9b34d83a5689bb7cc9e7aab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0035_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  72%|███████▏  | 36/50 [04:49<01:55,  8.22s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcef118c869f4dd3b566871a2291673d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0036_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3ac96439b77494f894436e14fc46b6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0036_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "740136b836b44dd39a0c4131c7e22355",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0036_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce8e76c2b3f4a59b5192fbe76cbf9cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0036_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffb17082de454c8ea38ae1c5ac71297d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0036_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e128ff3ba8a4d11a5784bdc0506eea8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0036_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "537e8ba88fff4e9f877261d3ed46b654",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0036_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe6dd09e964442ef9038d58167076c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0036_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d5bb7a2dd9845c3963aff5af97845a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0036_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  74%|███████▍  | 37/50 [04:57<01:46,  8.17s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "131a76fac18346089f98df8b2e4790a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0037_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acf967dfcb9d4229a22c1023ffd8a243",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0037_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57ca927e9672444f8a49948ff0ddb2c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0037_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a4ae65cf6034cb289a166db7554dfbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0037_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15d3203786a34f199474683608e64104",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0037_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2457ffacf2c04aafb1da342a9a9cf7b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0037_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85a7bf5f29e94a87ae354cab6bfc24d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0037_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "497b43e6c4e94a02b4fb837a71453e64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0037_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb8e3e7042874f4a90bf7853ec013d98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0037_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  76%|███████▌  | 38/50 [05:05<01:37,  8.10s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be920cf5bb3d47e2aab23cee078312bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0038_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62b09cd3ddfb439ca0e6013b4dd4a435",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0038_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5e26a3df5cb44d1817f10c0a7f7c631",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0038_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb4ba7a8e7a4985b5555dfe2e0b6903",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0038_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6cfb3ef174c41119b6df3f2b37aef83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0038_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1e5f9a2847948f1bb5220773a6d0dde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0038_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46e54712cc294cc8acdeb659c8d09987",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0038_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cfb971d5dd44b669c398c06ba425840",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0038_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab89e8e0098345c086d6c660e9d17552",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0038_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  78%|███████▊  | 39/50 [05:13<01:28,  8.03s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08fc5717b18b42f79db96977aa9a9196",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0039_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04053d63734244eb99d688bf96c2e4d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0039_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84fbd9e9b75a47a3b06ae51753ebd906",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0039_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10cfdde4eb4145e0a6cc86afb2f54bb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0039_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81b0102c63db41029aee0f9a42655514",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0039_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "880b28b093804f98b3bb84216798b4f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0039_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "068d5333f55e490da163fe2877247008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0039_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "705052dde7974cf497c60556329ec196",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0039_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a53afc56e2b0455b973fd7e6409289b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0039_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  80%|████████  | 40/50 [05:21<01:20,  8.09s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5e65d6cd85a4666b4be83f95398b657",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0040_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2584fb5967d845d2a8641464454b0327",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0040_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "616e04a37bc34b3ca797c55a7e998056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0040_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89f74eed3b1f4a549b8a37bb02b53b80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0040_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "709ba08b01754a4395588d9904e0f3d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0040_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abc5db4ca9ef48d1b9e1272c95c7b6cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0040_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "910b9cd103eb439d84096bfb02dbaa9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0040_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eed18f292be4ee1a80b2e4ef563373f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0040_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dccc2dc02684d098cd4fb1c7625cf60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0040_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  82%|████████▏ | 41/50 [05:29<01:13,  8.16s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4b4ae2c20354cd8a3ed4124a8a19dbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0041_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c9003f17dea414c94a981d175e97ee8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0041_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01be6c22ac114cb78f2d05f75ce90bf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0041_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9618802478a849e0b87aac96978ea037",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0041_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00de9105490443acb8b508ce640a241e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0041_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcd0305f9b544258bbb28a61ff6f24f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0041_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfc1b6416af740b9a1840181ecd0bb2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0041_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af5a4fcb9e044a3b861ef99608733a03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0041_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7fd7088ca884f14a8173c6fb6837a70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0041_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  84%|████████▍ | 42/50 [05:37<01:04,  8.04s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "652d984468c74b4bbde4f2e89331a854",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0042_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6454dcadff534ae1801652a2cc010483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0042_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d37db76329104eb39c80497e66fbec39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0042_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f3b07b992b542089c43f92e452615d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0042_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d29aa8a9c88478fb1d2f9a3e09e775c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0042_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceacb5c2ab294e8a930163387cfe1892",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0042_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcbc35d46db24195ac1595e87f7c1dfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0042_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51cdd8d3ab304eb98d9e382061fb0f76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0042_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4017c08568be4c6fbcdd1370c78b24d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0042_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  86%|████████▌ | 43/50 [05:45<00:55,  7.99s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ce584730ce24d7daac0fc6950600a9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0043_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "978cb765258c4219a528851cee57cf1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0043_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41f0856897e74944969d5fda1c8b447d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0043_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc07307d4d87463cbc5c0a7da0d8e082",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0043_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a50c6ef836d14807ab7a7f2670f09b55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0043_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3fdb1f7ca774eea81de6a8968257763",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0043_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e98afd2397847da96d90997e56f3000",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0043_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "724edf52e3b4416192908e7824db09c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0043_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81cd83c216d643c6b4d0dfda734e57f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0043_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  88%|████████▊ | 44/50 [05:53<00:48,  8.01s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85085a810e024769af27115b26e0a7b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0044_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2557ad7e20fc45abb493af2f76343b1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0044_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feba04c854f34f3a9411813e83e81bbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0044_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d11e155f5a9e4c3998b80dccd0220f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0044_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdd5eea9d0174b53a06aad0ee0f8998b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0044_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fbda4fc388045678ac4a96ef0bf4ac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0044_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba35e0d1c48c46d1a3777504e0f53a71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0044_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "622937f4f5464a5d9cf63445393c6148",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0044_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25e2c364022e4a21ba2992a88097e8fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0044_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  90%|█████████ | 45/50 [06:01<00:40,  8.08s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d211129471394c3c9d267c449cc1f629",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0045_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab17d4fb4a184effb8e8766338725bfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0045_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d74a84002694270bbc199d559459ac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0045_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18c810f159af44eaa80c316db648482d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0045_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3764835b0c74f4f80f491fa41c37dc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0045_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aba0a5c209054bc99982a696084a744a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0045_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3823bb4d9fd4d979df2ed07d9258bb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0045_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffc166243a2f45e4b14585964dcb4b04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0045_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c002d3691a14876ad113b9cd0ebe88a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0045_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  92%|█████████▏| 46/50 [06:10<00:32,  8.17s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6434d750f0684533adf6987c105fe70d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0046_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a650dc0cadae41138d2273d6fd1fa28e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0046_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b438a6d947714eb5a350e07af1d8ccc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0046_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf527f4c19504bbeb2cc65a235dcfa45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0046_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db73a493130544b98f83453eec3fd7c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0046_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f9a60c806c343e79839918c242178bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0046_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4989b131790341a98e375a02e1cdd7b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0046_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88c79e6c00374501b06c6ef1e4ef2818",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0046_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b624c56ee5e4a9fb544ed2b25b56d00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0046_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  94%|█████████▍| 47/50 [06:17<00:24,  8.07s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d0eb08dcb544a239a0f9a6ef3b253a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0047_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bebc6d17cfb94d0bb869c1fe3c9ea6ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0047_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be2f0b9388bc4833bc2bd2e68c1176df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0047_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7c1753b8c444fe0a3b0510325d53957",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0047_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73cbb80c575e447ea1cfb7d717f728f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0047_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a1effc62f2b4f3abd441be46b6e73ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0047_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f96500b6c83e4de2ac9fafdc38ec1607",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0047_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18dbfd9fa1dc4ff18eb0c0db5cb33b5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0047_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3e7d27dcd9645599a1ae3cb9b49a7a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0047_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  96%|█████████▌| 48/50 [06:26<00:16,  8.09s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1561bd8ae93a4a04894965954e112434",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0048_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "612aedeefc644378be975433f0f541da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0048_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73c1de98eac743a9abc7569a8c73ed91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0048_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34cef7e2e8434145bc07053160678dd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0048_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e1a495964c84060ad5bcde0b34ae6ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0048_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4f9d251aff7456ebefc0881b682a8be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0048_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c798c7f5fd7c4571875b8629fa8e9277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0048_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1970922311e048a18377392246170204",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0048_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bc24602d0bc45ad90e38168a48f5943",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0048_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress:  98%|█████████▊| 49/50 [06:33<00:08,  8.02s/it]"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38a46b6b448e408a899e8522bca2f8e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0049_2025_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaeb980c92c849888e0ac32359e71e3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0049_42_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7794c8dfb394c9faa8cde0fd3abc537",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/baseline/0049_1337_noneg.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6fc3a3ecefd427c9364361bdab702fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0049_2025_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdbd79d64b944668ad5d9f3506ad6519",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0049_42_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd16597f4eb5464c9d77de9707139de0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0/0049_1337_neg_s0.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e987bcc4f424605b0cd838ff8edca14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0049_2025_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d940ad73ec0447c987aeb8ebac34fcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0049_42_neg_s0p2.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0fa9d65bfe743ec979c34e94b8de1b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WRITE] turbo -> /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag/turbo/with_negative_start0p2/0049_1337_neg_s0p2.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "turbo progress: 100%|██████████| 50/50 [06:42<00:00,  8.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ turbo: Generated and saved 450 images\n",
            "\n",
            "============================================================\n",
            "✓ Total generated and saved: 450 images\n",
            "✓ Models tested: ['turbo']\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------- Load prompts from JSON file ----------\n",
        "prompts_file = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/data/prompts_noun_negative.json\"\n",
        "\n",
        "model_configs = {\n",
        "#    'base': {'steps': 30, 'recommended_cfg': 7.0},\n",
        "#    'dmd': {'steps': 4, 'recommended_cfg': 1.5},\n",
        "    'turbo': {'steps': 4, 'recommended_cfg': 0.0},\n",
        "#    'lightning': {'steps': 4, 'recommended_cfg': 0.0},\n",
        "#    'lcm': {'steps': 4, 'recommended_cfg': 1.5},\n",
        "#    'hyper': {'steps': 8, 'recommended_cfg': 5.0},\n",
        "#   'pcm': {'steps': 4, 'recommended_cfg': 3.0},\n",
        "}\n",
        "\n",
        "use_nag = True  # Set to True to use NAG pipeline, False for standard SDXL pipeline\n",
        "\n",
        "# ---- Fixed seeds for reproducibility (3 seeds) ----\n",
        "fixed_seeds = [2025, 42, 1337]  \n",
        "\n",
        "# Load prompts\n",
        "with open(prompts_file, 'r') as f:\n",
        "    prompts_data = json.load(f)\n",
        "\n",
        "# ---- Select top 50 prompts ----\n",
        "if isinstance(prompts_data, list) and len(prompts_data) > 0 and isinstance(prompts_data[0], dict) and 'score' in prompts_data[0]:\n",
        "    prompts_data = sorted(prompts_data, key=lambda x: x.get('score', 0), reverse=True)[:50]\n",
        "else:\n",
        "    prompts_data = prompts_data[:50]\n",
        "\n",
        "print(f\"Loaded {len(prompts_data)} prompts from {prompts_file}\")\n",
        "print(f\"[CONFIG] use_nag={use_nag} | models={list(model_configs.keys())}\\n\")\n",
        "\n",
        "# ---------- Generate and save images organised by folder ----------\n",
        "total_generated = 0\n",
        "\n",
        "for model_name, model_config in model_configs.items():\n",
        "    steps = model_config[\"steps\"]\n",
        "    cfg = model_config[\"recommended_cfg\"]\n",
        "\n",
        "    # ---- Choose pipeline + base output dir first (so we can print paths clearly)\n",
        "    if use_nag:\n",
        "        pipeline_cls = NAGTimeStableDiffusionXLPipeline\n",
        "        output_base_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results-nag\"\n",
        "    else:\n",
        "        pipeline_cls = StableDiffusionXLPipeline\n",
        "        output_base_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results\"\n",
        "\n",
        "    # Load the model pipeline\n",
        "    print(f\"[MODEL] {model_name} -> steps={steps}, cfg={cfg}\")\n",
        "    print(f\"[PIPELINE] {pipeline_cls.__name__}\")\n",
        "    pipe = load_pipe(pipeline_cls, model_name)\n",
        "\n",
        "    # Create model-specific output directories\n",
        "    model_output_dir = os.path.join(output_base_dir, model_name)\n",
        "\n",
        "    if use_nag:\n",
        "        baseline_dir  = os.path.join(model_output_dir, \"baseline\")\n",
        "        withneg0_dir  = os.path.join(model_output_dir, \"with_negative_start0\")\n",
        "        withneg02_dir = os.path.join(model_output_dir, \"with_negative_start0p2\")\n",
        "\n",
        "        os.makedirs(baseline_dir, exist_ok=True)\n",
        "        os.makedirs(withneg0_dir, exist_ok=True)\n",
        "        os.makedirs(withneg02_dir, exist_ok=True)\n",
        "\n",
        "        print(\"\\n[DIRS]\")\n",
        "        print(f\"  base_output: {output_base_dir}\")\n",
        "        print(f\"  model_root : {model_output_dir}\")\n",
        "        print(f\"  baseline   : {baseline_dir}\")\n",
        "        print(f\"  neg@0.0    : {withneg0_dir}\")\n",
        "        print(f\"  neg@0.2    : {withneg02_dir}\")\n",
        "    else:\n",
        "        baseline_dir = os.path.join(model_output_dir, \"baseline\")\n",
        "        withneg_dir  = os.path.join(model_output_dir, \"with_negative\")\n",
        "\n",
        "        os.makedirs(baseline_dir, exist_ok=True)\n",
        "        os.makedirs(withneg_dir, exist_ok=True)\n",
        "\n",
        "        print(\"\\n[DIRS]\")\n",
        "        print(f\"  base_output: {output_base_dir}\")\n",
        "        print(f\"  model_root : {model_output_dir}\")\n",
        "        print(f\"  baseline   : {baseline_dir}\")\n",
        "        print(f\"  with_neg   : {withneg_dir}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Testing model: {model_name}\")\n",
        "    print(f\"Writing under: {model_output_dir}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    generated_count = 0\n",
        "\n",
        "    for idx, item in enumerate(tqdm(prompts_data[:10], desc=f\"{model_name} progress\")):\n",
        "        prompt = item[\"prompt\"]\n",
        "        negative_prompt = item.get(\"negative_prompt\", \"\")\n",
        "\n",
        "        if use_nag:\n",
        "            # --- NAG branch: run three passes as requested ---\n",
        "            runs = [\n",
        "                # 1) once with no negative (baseline folder)\n",
        "                {\"out_dir\": baseline_dir,  \"neg\": False, \"nag_start\": None, \"neg_label\": \"noneg\"},\n",
        "                # 2) once with negative, start=0\n",
        "                {\"out_dir\": withneg0_dir,  \"neg\": True,  \"nag_start\": 0.0,  \"neg_label\": \"neg_s0\"},\n",
        "                # 3) once with negative, start=0.2\n",
        "                {\"out_dir\": withneg02_dir, \"neg\": True,  \"nag_start\": 0.2,  \"neg_label\": \"neg_s0p2\"},\n",
        "            ]\n",
        "\n",
        "            for run in runs:\n",
        "                for seed in fixed_seeds:\n",
        "                    try:\n",
        "                        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "                        # Build kwargs; only pass nag_start when specified\n",
        "                        call_kwargs = dict(\n",
        "                            prompt=prompt,\n",
        "                            guidance_scale=cfg,\n",
        "                            num_inference_steps=steps,\n",
        "                            generator=generator\n",
        "                        )\n",
        "\n",
        "                        # Negative prompt handling\n",
        "                        if run[\"neg\"]:\n",
        "                            call_kwargs[\"nag_negative_prompt\"] = negative_prompt if negative_prompt else None\n",
        "                        else:\n",
        "                            call_kwargs[\"nag_negative_prompt\"] = None\n",
        "\n",
        "                        if run[\"nag_start\"] is not None:\n",
        "                            call_kwargs[\"nag_start\"] = run[\"nag_start\"]\n",
        "\n",
        "                        image = pipe(**call_kwargs).images[0]\n",
        "\n",
        "                        filename = f\"{idx:04d}_{seed}_{run['neg_label']}.png\"\n",
        "                        filepath = os.path.join(run[\"out_dir\"], filename)\n",
        "\n",
        "                        # ---- Print exactly where we're writing\n",
        "                        print(f\"[WRITE] {model_name} -> {filepath}\")\n",
        "                        image.save(filepath)\n",
        "\n",
        "                        generated_count += 1\n",
        "                        total_generated += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"[ERROR] model={model_name}, prompt_idx={idx}, seed={seed}, run={run['neg_label']} -> {e}\")\n",
        "                        continue\n",
        "\n",
        "        else:\n",
        "            # Run both conditions: without negatives (baseline) and with negatives\n",
        "            for use_negative in [False, True]:\n",
        "                out_dir = withneg_dir if use_negative else baseline_dir\n",
        "                neg_label = \"neg\" if use_negative else \"noneg\"\n",
        "\n",
        "                for seed in fixed_seeds:\n",
        "                    try:\n",
        "                        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "                        image = pipe(\n",
        "                            prompt,\n",
        "                            negative_prompt=negative_prompt if use_negative else None,\n",
        "                            guidance_scale=cfg,\n",
        "                            num_inference_steps=steps,\n",
        "                            generator=generator\n",
        "                        ).images[0]\n",
        "                        \n",
        "                        filename = f\"{idx:04d}_{seed}_{neg_label}.png\"\n",
        "                        filepath = os.path.join(out_dir, filename)\n",
        "\n",
        "                        # ---- Print exactly where we're writing\n",
        "                        print(f\"[WRITE] {model_name} -> {filepath}\")\n",
        "                        image.save(filepath)\n",
        "\n",
        "                        generated_count += 1\n",
        "                        total_generated += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"[ERROR] model={model_name}, prompt_idx={idx}, seed={seed}, use_negative={use_negative} -> {e}\")\n",
        "                        continue\n",
        "    \n",
        "    print(f\"\\n✓ {model_name}: Generated and saved {generated_count} images\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"✓ Total generated and saved: {total_generated} images\")\n",
        "print(f\"✓ Models tested: {list(model_configs.keys())}\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "nag"
    },
    "kernelspec": {
      "display_name": "NAG (Python 3.13)",
      "language": "python",
      "name": "nag"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
