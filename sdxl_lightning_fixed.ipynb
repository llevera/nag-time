{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef94728",
   "metadata": {},
   "source": [
    "# SDXL Model Pipeline Setup - Lightning Fix Applied\n",
    "Supports 9 distillation models with proper scheduler configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02129d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports completed\n",
      "✓ Configuration set - Device: cuda, Dtype: torch.bfloat16\n",
      "✓ Available models: ['dmd', 'turbo', 'lightning', 'lcm', 'hyper', 'pcm', 'tcd', 'flash']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.13/site-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  self.setter(val)\n"
     ]
    }
   ],
   "source": [
    "# Imports and Configuration\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import (\n",
    "    UNet2DConditionModel,\n",
    "    StableDiffusionXLPipeline,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    DDIMScheduler,\n",
    "    LCMScheduler,\n",
    "    TCDScheduler,\n",
    "    DiffusionPipeline,\n",
    ")\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"✓ Imports completed\")\n",
    "\n",
    "# ---------- Configuration ----------\n",
    "device = \"cuda\"\n",
    "weights_dtype = torch.bfloat16\n",
    "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "model_configs = {\n",
    "#    'base': {'steps': 100, 'recommended_cfg': 5.0},\n",
    "    'dmd': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'turbo': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'lightning': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'lcm': {'steps': 4, 'recommended_cfg': 1.0},\n",
    "    'hyper': {'steps': 8, 'recommended_cfg': 5.0},\n",
    "    'pcm': {'steps': 4, 'recommended_cfg': 2.0},\n",
    "    'tcd': {'steps': 4, 'recommended_cfg': 3.0},\n",
    "    'flash': {'steps': 4, 'recommended_cfg': 2.0}\n",
    "}\n",
    "\n",
    "print(f\"✓ Configuration set - Device: {device}, Dtype: {weights_dtype}\")\n",
    "print(f\"✓ Available models: {list(model_configs.keys())}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_model(distillation_type=None, weights_dtype=torch.float16, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load SDXL models with specified distillation type.\n",
    "    \n",
    "    Returns:\n",
    "      'base'/'None': (pipe, base_unet, base_scheduler)\n",
    "      others:       (pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler)\n",
    "    \"\"\"\n",
    "    kind = ('base' if distillation_type in (None, 'base') else distillation_type).lower()\n",
    "    print(f\"Loading {kind.upper()} model...\")\n",
    "\n",
    "    # ---- base (always build this once for config/safety) ----\n",
    "    base_unet = UNet2DConditionModel.from_pretrained(\n",
    "        basemodel_id, subfolder=\"unet\", torch_dtype=weights_dtype\n",
    "    ).to(device)\n",
    "\n",
    "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        basemodel_id,\n",
    "        unet=base_unet,\n",
    "        torch_dtype=weights_dtype,\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    base_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.scheduler = base_scheduler\n",
    "    pipe.to(device=device, dtype=weights_dtype)\n",
    "\n",
    "    if kind == 'base':\n",
    "        return pipe, base_unet, base_scheduler\n",
    "\n",
    "    # fresh UNet matching base config (required for state_dict load)\n",
    "    distilled_unet = UNet2DConditionModel.from_config(pipe.unet.config).to(device, dtype=weights_dtype)\n",
    "\n",
    "    if kind == 'dmd':\n",
    "        repo_name, ckpt_name = \"tianweiy/DMD2\", \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
    "        state = torch.load(hf_hub_download(repo_name, ckpt_name), map_location='cpu')\n",
    "        distilled_unet.load_state_dict(state if isinstance(state, dict) else state['state_dict'])\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'lightning':\n",
    "        repo, ckpt = \"ByteDance/SDXL-Lightning\", \"sdxl_lightning_4step_unet.safetensors\"\n",
    "        state = load_file(hf_hub_download(repo, ckpt))\n",
    "        distilled_unet.load_state_dict(state, strict=True)\n",
    "        # FIX: Use EulerDiscreteScheduler with trailing timesteps for both schedulers\n",
    "        distilled_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "        base_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'turbo':\n",
    "        # turbo ships a full UNet; pull that directly\n",
    "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"stabilityai/sdxl-turbo\", subfolder=\"unet\", torch_dtype=weights_dtype, variant=\"fp16\"\n",
    "        ).to(device)\n",
    "        distilled_scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'lcm':\n",
    "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"latent-consistency/lcm-sdxl\", torch_dtype=weights_dtype\n",
    "        ).to(device)\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'hyper':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"ByteDance/Hyper-SD\",\n",
    "                               weight_name=\"Hyper-SDXL-8steps-CFG-lora.safetensors\",\n",
    "                               adapter_name=\"hyper-sdxl-8step\")\n",
    "        pipe.set_adapters([\"hyper-sdxl-8step\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'pcm':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"wangfuyun/PCM_Weights\",\n",
    "                               weight_name=\"pcm_sdxl_smallcfg_4step_converted.safetensors\",\n",
    "                               subfolder=\"sdxl\",\n",
    "                               adapter_name=\"pcm-lora\")\n",
    "        pipe.set_adapters([\"pcm-lora\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'tcd':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"h1t/TCD-SDXL-LoRA\", adapter_name=\"tcd-lora\")\n",
    "        pipe.set_adapters([\"tcd-lora\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'flash':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"jasperai/flash-sdxl\",\n",
    "                               weight_name=\"pytorch_lora_weights.safetensors\",\n",
    "                               adapter_name=\"flash-sdxl\")\n",
    "        pipe.set_adapters([\"flash-sdxl\"], adapter_weights=[1.0])\n",
    "        pipe.fuse_lora()\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distillation type: '{distillation_type}'. \"\n",
    "                         f\"Available: {', '.join(sorted(model_configs.keys()))}\")\n",
    "\n",
    "    # IMPORTANT: actually use the distilled UNet\n",
    "    if hasattr(pipe, \"unet\") and distilled_unet is not pipe.unet:\n",
    "        pipe.unet = distilled_unet\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.to(device=device, dtype=weights_dtype)\n",
    "    return pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler\n",
    "\n",
    "\n",
    "def load_pipe(distillation_type='base'):\n",
    "    \"\"\"\n",
    "    Returns a ready-to-sample pipeline with the correct UNet and scheduler.\n",
    "    \"\"\"\n",
    "    pipe_result = load_model(distillation_type, weights_dtype, device)\n",
    "    # result already sets the right scheduler/UNet when not 'base'\n",
    "    pipe = pipe_result[0]\n",
    "    print(f\"✓ {('base' if distillation_type in (None, 'base') else distillation_type).upper()} pipeline ready\")\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0adb1",
   "metadata": {},
   "source": [
    "## Test Across Select Models\n",
    "Run tests on multiple models with first 10 prompts and first seed, organized by model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 prompts from /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/data/prompts_noun_negative.json\n",
      "Output base directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results\n",
      "Loading DMD model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abdef61f9a044f9bf3d3ae8f7ed4c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "The config attributes {'interpolation_type': 'linear', 'use_karras_sigmas': False, 'skip_prk_steps': True} were passed to LCMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DMD pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: dmd\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/dmd\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ad3b8bcfec4e929d3c953a7dd5dc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  10%|█         | 1/10 [00:01<00:13,  1.49s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6484d6eea0c409eb85749cf7cb6d57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  20%|██        | 2/10 [00:02<00:09,  1.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccfdbf3e6dd44d188b16b383ba44a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  30%|███       | 3/10 [00:03<00:07,  1.06s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f99a98f9364c7385b4c73eeb81607e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  40%|████      | 4/10 [00:04<00:06,  1.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b8e670a2844b19a33eb3e49d0bfbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  50%|█████     | 5/10 [00:05<00:05,  1.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd27f90bc3a45e19624a0e531fa2070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  60%|██████    | 6/10 [00:06<00:04,  1.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161aa2a2201e4dce81f3a826f75e206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  70%|███████   | 7/10 [00:07<00:03,  1.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e5cbca37b34f69a3261004d73d8520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  80%|████████  | 8/10 [00:08<00:02,  1.06s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7501220099b149adb19dbda7a1c3f28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress:  90%|█████████ | 9/10 [00:09<00:01,  1.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18e9ed8a03949958b673749eaebe153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmd progress: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ dmd: Generated and saved 10 images\n",
      "Loading TURBO model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9a85b4c7814f12869890bb9ca7abce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TURBO pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: turbo\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/turbo\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141145494ef74ce3a522abb14140e972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  10%|█         | 1/10 [00:00<00:07,  1.15it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8bdd7df50e491aaa8ec2a92fa1f742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  20%|██        | 2/10 [00:01<00:07,  1.07it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee258d9e3ee84516b5bce283ebfb11b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  30%|███       | 3/10 [00:02<00:06,  1.06it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d37d83a870c4dcdb8add9c467a3a9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  40%|████      | 4/10 [00:03<00:05,  1.05it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8b20c11c4b4a15b99f9e59fe9248a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  50%|█████     | 5/10 [00:04<00:04,  1.04it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3ab236f2ac4c17b2197c5ff59cd920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  60%|██████    | 6/10 [00:05<00:03,  1.09it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f680439184ae18fa55423eaaef2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  70%|███████   | 7/10 [00:06<00:02,  1.07it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757c662639634ebea1b2d6e66e98e0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  80%|████████  | 8/10 [00:07<00:01,  1.05it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462c079c18f344ce9a45bdf32b678b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress:  90%|█████████ | 9/10 [00:08<00:00,  1.06it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a8eb491faa4b0c95e35a9ede209fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "turbo progress: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ turbo: Generated and saved 10 images\n",
      "Loading LIGHTNING model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd121c7b140469182e3480850a4c99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LIGHTNING pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: lightning\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/lightning\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59d0cf10955460c9e7827ae31d30465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  10%|█         | 1/10 [00:00<00:08,  1.08it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29842e624df4c508fa77aef6e5f8048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  20%|██        | 2/10 [00:01<00:07,  1.00it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37babeafac14d4c90c54e3fa22bdf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  30%|███       | 3/10 [00:02<00:06,  1.08it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e83376167a34163b4961d76d9fc56e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  40%|████      | 4/10 [00:03<00:05,  1.03it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ac25c21d1b44e5b75c509d9104fe91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  50%|█████     | 5/10 [00:04<00:05,  1.01s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4472c62bf3043b383f0c9c03c15b55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  60%|██████    | 6/10 [00:05<00:03,  1.02it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725fd4335708498e92717b350ce31b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  70%|███████   | 7/10 [00:06<00:02,  1.03it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde57582fcc54b17b4cd42b39badb694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  80%|████████  | 8/10 [00:07<00:01,  1.02it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2026fbd0d6b3456bb6faeddb502a3ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress:  90%|█████████ | 9/10 [00:08<00:00,  1.00it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2885de138c2641c389514795a52eb1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightning progress: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ lightning: Generated and saved 10 images\n",
      "Loading LCM model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d254af78934f03b8de7f3a6c5df457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'interpolation_type': 'linear', 'use_karras_sigmas': False, 'skip_prk_steps': True} were passed to LCMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LCM pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: lcm\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/lcm\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549a677ae8c6476b929b31fc7cf3ba28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  10%|█         | 1/10 [00:00<00:08,  1.08it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d769a94ebd46ccaca803604e69224b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  20%|██        | 2/10 [00:01<00:07,  1.02it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2520e4fd681e40c19b353b296d938e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  30%|███       | 3/10 [00:02<00:06,  1.05it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f2565d169c46379565da61f5972af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  40%|████      | 4/10 [00:03<00:06,  1.00s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea368ffbc9548eca799c395375876fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  50%|█████     | 5/10 [00:05<00:05,  1.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6690e7ce8def41abb9e9e585157ddb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  60%|██████    | 6/10 [00:05<00:04,  1.01s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411571a725b54f769ee85d01f810a566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  70%|███████   | 7/10 [00:06<00:02,  1.01it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a714612106428eb86e5dee397998b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  80%|████████  | 8/10 [00:07<00:01,  1.01it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63d6540f4eb4923a51b397ba850cc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress:  90%|█████████ | 9/10 [00:08<00:00,  1.01it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33898871e744f0a8d7a138341a24859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lcm progress: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ lcm: Generated and saved 10 images\n",
      "Loading HYPER model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaffe4e6978e4a23ae42c4d816eaac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7983da627c64de5a4e40b16484f5371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1aede379d5b4495a492637ce769d642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hyper-SDXL-8steps-CFG-lora.safetensors:   0%|          | 0.00/787M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Load prompts from JSON file ----------\n",
    "prompts_file = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/data/prompts_noun_negative.json\"\n",
    "output_base_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results\"\n",
    "\n",
    "# Load prompts\n",
    "with open(prompts_file, 'r') as f:\n",
    "    prompts_data = json.load(f)\n",
    "\n",
    "# Use only first 10 prompts\n",
    "prompts_data = prompts_data[:10]\n",
    "\n",
    "print(f\"Loaded {len(prompts_data)} prompts from {prompts_file}\")\n",
    "print(f\"Output base directory: {output_base_dir}\")\n",
    "\n",
    "# ---------- Generate and save images organized by folder ----------\n",
    "total_generated = 0\n",
    "\n",
    "for model_name, model_config in model_configs.items():\n",
    "    steps = model_config[\"steps\"]\n",
    "    cfg = model_config[\"recommended_cfg\"]\n",
    "    \n",
    "    # Load the model pipeline\n",
    "    pipe = load_pipe(model_name)\n",
    "    \n",
    "    # Create model-specific output directory\n",
    "    model_output_dir = os.path.join(output_base_dir, model_name)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing model: {model_name}\")\n",
    "    print(f\"Output directory: {model_output_dir}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    generated_count = 0\n",
    "    \n",
    "    for idx, item in enumerate(tqdm(prompts_data, desc=f\"{model_name} progress\")):\n",
    "        prompt = item[\"prompt\"]\n",
    "        negative_prompt = item[\"negative_prompt\"]\n",
    "        seeds = item.get(\"seeds\", [42])\n",
    "        \n",
    "        # Use first seed for quick generation\n",
    "        seed = 2014\n",
    "        \n",
    "        try:\n",
    "            # Generate image\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "            image = pipe(\n",
    "                prompt,\n",
    "                guidance_scale=cfg,\n",
    "                num_inference_steps=steps,\n",
    "                generator=generator\n",
    "            ).images[0]\n",
    "            \n",
    "            # Create output filename\n",
    "            group = item.get(\"group\", \"unknown\")\n",
    "            filename = f\"{idx:04d}_{group}_{seed}.png\"\n",
    "            filepath = os.path.join(model_output_dir, filename)\n",
    "            \n",
    "            # Save image\n",
    "            image.save(filepath)\n",
    "            generated_count += 1\n",
    "            total_generated += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image for prompt {idx} with {model_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n✓ {model_name}: Generated and saved {generated_count} images\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ Total generated and saved: {total_generated} images\")\n",
    "print(f\"✓ Models tested: {list(model_configs.keys())}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAG (Python 3.13)",
   "language": "python",
   "name": "nag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
