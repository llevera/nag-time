{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef94728",
   "metadata": {},
   "source": [
    "# SDXL Model Pipeline Setup - Lightning Fix Applied\n",
    "Supports 9 distillation models with proper scheduler configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02129d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "✓ Imports completed\n",
      "✓ Configuration set - Device: cuda, Dtype: torch.bfloat16\n",
      "✓ Available models: ['base', 'dmd', 'turbo', 'lightning', 'lcm', 'hyper', 'pcm', 'tcd', 'flash']\n"
     ]
    }
   ],
   "source": [
    "# Imports and Configuration\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import (\n",
    "    UNet2DConditionModel,\n",
    "    StableDiffusionXLPipeline,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    DDIMScheduler,\n",
    "    LCMScheduler,\n",
    "    TCDScheduler,\n",
    "    DiffusionPipeline,\n",
    ")\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"✓ Imports completed\")\n",
    "\n",
    "# ---------- Configuration ----------\n",
    "device = \"cuda\"\n",
    "weights_dtype = torch.bfloat16\n",
    "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "model_configs = {\n",
    "    'base': {'steps': 100, 'recommended_cfg': 5.0},\n",
    "    'dmd': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'turbo': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'lightning': {'steps': 4, 'recommended_cfg': 0.0},\n",
    "    'lcm': {'steps': 4, 'recommended_cfg': 1.0},\n",
    "    'hyper': {'steps': 8, 'recommended_cfg': 5.0},\n",
    "    'pcm': {'steps': 4, 'recommended_cfg': 2.0},\n",
    "    'tcd': {'steps': 4, 'recommended_cfg': 3.0},\n",
    "    'flash': {'steps': 4, 'recommended_cfg': 2.0}\n",
    "}\n",
    "\n",
    "print(f\"✓ Configuration set - Device: {device}, Dtype: {weights_dtype}\")\n",
    "print(f\"✓ Available models: {list(model_configs.keys())}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_model(distillation_type=None, weights_dtype=torch.float16, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load SDXL models with specified distillation type.\n",
    "    \n",
    "    Returns:\n",
    "      'base'/'None': (pipe, base_unet, base_scheduler)\n",
    "      others:       (pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler)\n",
    "    \"\"\"\n",
    "    kind = ('base' if distillation_type in (None, 'base') else distillation_type).lower()\n",
    "    print(f\"Loading {kind.upper()} model...\")\n",
    "\n",
    "    # ---- base (always build this once for config/safety) ----\n",
    "    base_unet = UNet2DConditionModel.from_pretrained(\n",
    "        basemodel_id, subfolder=\"unet\", torch_dtype=weights_dtype\n",
    "    ).to(device)\n",
    "\n",
    "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        basemodel_id,\n",
    "        unet=base_unet,\n",
    "        torch_dtype=weights_dtype,\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    base_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.scheduler = base_scheduler\n",
    "    pipe.to(device=device, dtype=weights_dtype)\n",
    "\n",
    "    if kind == 'base':\n",
    "        return pipe, base_unet, base_scheduler\n",
    "\n",
    "    # fresh UNet matching base config (required for state_dict load)\n",
    "    distilled_unet = UNet2DConditionModel.from_config(pipe.unet.config).to(device, dtype=weights_dtype)\n",
    "\n",
    "    if kind == 'dmd':\n",
    "        repo_name, ckpt_name = \"tianweiy/DMD2\", \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
    "        state = torch.load(hf_hub_download(repo_name, ckpt_name), map_location='cpu')\n",
    "        distilled_unet.load_state_dict(state if isinstance(state, dict) else state['state_dict'])\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'lightning':\n",
    "        repo, ckpt = \"ByteDance/SDXL-Lightning\", \"sdxl_lightning_4step_unet.safetensors\"\n",
    "        state = load_file(hf_hub_download(repo, ckpt))\n",
    "        distilled_unet.load_state_dict(state, strict=True)\n",
    "        # FIX: Use EulerDiscreteScheduler with trailing timesteps for both schedulers\n",
    "        distilled_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "        base_scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'turbo':\n",
    "        # turbo ships a full UNet; pull that directly\n",
    "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"stabilityai/sdxl-turbo\", subfolder=\"unet\", torch_dtype=weights_dtype, variant=\"fp16\"\n",
    "        ).to(device)\n",
    "        distilled_scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'lcm':\n",
    "        distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"latent-consistency/lcm-sdxl\", torch_dtype=weights_dtype\n",
    "        ).to(device)\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'hyper':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"ByteDance/Hyper-SD\",\n",
    "                               weight_name=\"Hyper-SDXL-8steps-CFG-lora.safetensors\",\n",
    "                               adapter_name=\"hyper-sdxl-8step\")\n",
    "        pipe.set_adapters([\"hyper-sdxl-8step\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'pcm':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"wangfuyun/PCM_Weights\",\n",
    "                               weight_name=\"pcm_sdxl_smallcfg_4step_converted.safetensors\",\n",
    "                               subfolder=\"sdxl\",\n",
    "                               adapter_name=\"pcm-lora\")\n",
    "        pipe.set_adapters([\"pcm-lora\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = DDIMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    elif kind == 'tcd':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"h1t/TCD-SDXL-LoRA\", adapter_name=\"tcd-lora\")\n",
    "        pipe.set_adapters([\"tcd-lora\"], adapter_weights=[1.0])\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    elif kind == 'flash':\n",
    "        pipe = DiffusionPipeline.from_pretrained(basemodel_id, torch_dtype=weights_dtype)\n",
    "        pipe.load_lora_weights(\"jasperai/flash-sdxl\",\n",
    "                               weight_name=\"pytorch_lora_weights.safetensors\",\n",
    "                               adapter_name=\"flash-sdxl\")\n",
    "        pipe.set_adapters([\"flash-sdxl\"], adapter_weights=[1.0])\n",
    "        pipe.fuse_lora()\n",
    "        distilled_unet = pipe.unet\n",
    "        distilled_scheduler = LCMScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distillation type: '{distillation_type}'. \"\n",
    "                         f\"Available: {', '.join(sorted(model_configs.keys()))}\")\n",
    "\n",
    "    # IMPORTANT: actually use the distilled UNet\n",
    "    if hasattr(pipe, \"unet\") and distilled_unet is not pipe.unet:\n",
    "        pipe.unet = distilled_unet\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.to(device=device, dtype=weights_dtype)\n",
    "    return pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler\n",
    "\n",
    "\n",
    "def load_pipe(distillation_type='base', weights_dtype=torch.float16, device='cuda'):\n",
    "    \"\"\"\n",
    "    Returns a ready-to-sample pipeline with the correct UNet and scheduler.\n",
    "    \"\"\"\n",
    "    pipe_result = load_model(distillation_type, weights_dtype, device)\n",
    "    # result already sets the right scheduler/UNet when not 'base'\n",
    "    pipe = pipe_result[0]\n",
    "    print(f\"✓ {('base' if distillation_type in (None, 'base') else distillation_type).upper()} pipeline ready\")\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0adb1",
   "metadata": {},
   "source": [
    "## Test Across Select Models\n",
    "Run tests on multiple models with first 10 prompts and first seed, organized by model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1774ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 prompts from /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/data/prompts_noun_negative.json\n",
      "Output base directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results\n",
      "Loading BASE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BASE pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: base\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/base\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.68it/s]t/s]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.78it/s],  8.78s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.86it/s],  8.76s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.95it/s],  8.71s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.92it/s],  8.67s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.92it/s],  8.65s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.92it/s],  8.64s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.95it/s],  8.63s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.94it/s],  8.62s/it]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.91it/s],  8.61s/it]\n",
      "base progress: 100%|██████████| 10/10 [01:26<00:00,  8.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ base: Generated and saved 10 images\n",
      "Loading DMD model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 10.09it/s]\n",
      "The config attributes {'interpolation_type': 'linear', 'use_karras_sigmas': False, 'skip_prk_steps': True} were passed to LCMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DMD pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: dmd\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/dmd\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.20it/s] ?it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.77it/s]:08,  1.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.01it/s]:06,  1.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.03it/s]:04,  1.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.01it/s]:03,  1.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.03it/s]:03,  1.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.05it/s]:02,  1.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.07it/s]:01,  1.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.07it/s]:01,  1.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.13it/s]:00,  1.73it/s]\n",
      "dmd progress: 100%|██████████| 10/10 [00:06<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ dmd: Generated and saved 10 images\n",
      "Loading TURBO model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TURBO pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: turbo\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/turbo\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 12.04it/s]?, ?it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.88it/s]00:04,  1.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.08it/s]00:04,  1.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.09it/s]00:03,  1.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.07it/s]00:03,  1.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.08it/s]00:02,  1.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.94it/s]00:02,  1.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.72it/s]00:01,  1.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.92it/s]00:01,  1.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.95it/s]00:00,  1.78it/s]\n",
      "turbo progress: 100%|██████████| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ turbo: Generated and saved 10 images\n",
      "Loading LIGHTNING model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LIGHTNING pipeline ready\n",
      "\n",
      "============================================================\n",
      "Testing model: lightning\n",
      "Output directory: /home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results/lightning\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.91it/s]:00<?, ?it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.05it/s]:00<00:04,  1.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.99it/s]:01<00:04,  1.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.66it/s]:01<00:03,  1.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.77it/s]:02<00:03,  1.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.88it/s]:02<00:02,  1.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.89it/s]:03<00:02,  1.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.31it/s]:03<00:01,  1.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.69it/s]:04<00:01,  1.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.55it/s]:05<00:00,  1.78it/s]\n",
      "lightning progress: 100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ lightning: Generated and saved 10 images\n",
      "Loading LCM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.63it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Data processing error: CAS service error : IO Error: No space left on device (os error 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m cfg \u001b[38;5;241m=\u001b[39m model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecommended_cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Load the model pipeline\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mload_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create model-specific output directory\u001b[39;00m\n\u001b[1;32m     31\u001b[0m model_output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_base_dir, model_name)\n",
      "Cell \u001b[0;32mIn[17], line 156\u001b[0m, in \u001b[0;36mload_pipe\u001b[0;34m(distillation_type, weights_dtype, device)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_pipe\u001b[39m(distillation_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    Returns a ready-to-sample pipeline with the correct UNet and scheduler.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     pipe_result \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistillation_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# result already sets the right scheduler/UNet when not 'base'\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m pipe_result[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[17], line 99\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(distillation_type, weights_dtype, device)\u001b[0m\n\u001b[1;32m     96\u001b[0m     distilled_scheduler \u001b[38;5;241m=\u001b[39m EulerAncestralDiscreteScheduler\u001b[38;5;241m.\u001b[39mfrom_config(pipe\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mconfig, timestep_spacing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrailing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlcm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m     distilled_unet \u001b[38;5;241m=\u001b[39m \u001b[43mUNet2DConditionModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatent-consistency/lcm-sdxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_dtype\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    102\u001b[0m     distilled_scheduler \u001b[38;5;241m=\u001b[39m LCMScheduler\u001b[38;5;241m.\u001b[39mfrom_config(pipe\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyper\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:1193\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m use_safetensors:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m         resolved_model_file \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_add_variant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAFETENSORS_WEIGHTS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdduf_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdduf_entries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1209\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while trying to fetch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/utils/hub_utils.py:289\u001b[0m, in \u001b[0;36m_get_model_file\u001b[0;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, dduf_entries)\u001b[0m\n\u001b[1;32m    283\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are loading the variant \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m via `revision=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` instead. However, it appears that \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m currently does not have a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(weights_name,\u001b[38;5;250m \u001b[39mrevision)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m branch of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is missing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(weights_name,\u001b[38;5;250m \u001b[39mrevision)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m so that the correct variant file can be added.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    286\u001b[0m         )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# 2. Load model file as usual\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     model_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_file\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Data processing error: CAS service error : IO Error: No space left on device (os error 28)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Load prompts from JSON file ----------\n",
    "prompts_file = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/data/prompts_noun_negative.json\"\n",
    "output_base_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance/results\"\n",
    "\n",
    "# Load prompts\n",
    "with open(prompts_file, 'r') as f:\n",
    "    prompts_data = json.load(f)\n",
    "\n",
    "# Use only first 10 prompts\n",
    "prompts_data = prompts_data[:10]\n",
    "\n",
    "print(f\"Loaded {len(prompts_data)} prompts from {prompts_file}\")\n",
    "print(f\"Output base directory: {output_base_dir}\")\n",
    "\n",
    "# ---------- Generate and save images organized by folder ----------\n",
    "total_generated = 0\n",
    "\n",
    "for model_name, model_config in model_configs.items():\n",
    "    steps = model_config[\"steps\"]\n",
    "    cfg = model_config[\"recommended_cfg\"]\n",
    "    \n",
    "    # Load the model pipeline\n",
    "    pipe = load_pipe(model_name, weights_dtype=weights_dtype, device=device)\n",
    "    \n",
    "    # Create model-specific output directory\n",
    "    model_output_dir = os.path.join(output_base_dir, model_name)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing model: {model_name}\")\n",
    "    print(f\"Output directory: {model_output_dir}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    generated_count = 0\n",
    "    \n",
    "    for idx, item in enumerate(tqdm(prompts_data, desc=f\"{model_name} progress\")):\n",
    "        prompt = item[\"prompt\"]\n",
    "        negative_prompt = item[\"negative_prompt\"]\n",
    "        seeds = item.get(\"seeds\", [42])\n",
    "        \n",
    "        # Use first seed for quick generation\n",
    "        seed = seeds[0]\n",
    "        \n",
    "        try:\n",
    "            # Generate image\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "            image = pipe(\n",
    "                prompt,\n",
    "                guidance_scale=cfg,\n",
    "                num_inference_steps=steps,\n",
    "                generator=generator,\n",
    "                width=512, height=512,\n",
    "            ).images[0]\n",
    "            \n",
    "            # Create output filename\n",
    "            group = item.get(\"group\", \"unknown\")\n",
    "            filename = f\"{idx:04d}_{group}_{seed}.png\"\n",
    "            filepath = os.path.join(model_output_dir, filename)\n",
    "            \n",
    "            # Save image\n",
    "            image.save(filepath)\n",
    "            generated_count += 1\n",
    "            total_generated += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image for prompt {idx} with {model_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n✓ {model_name}: Generated and saved {generated_count} images\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ Total generated and saved: {total_generated} images\")\n",
    "print(f\"✓ Models tested: {list(model_configs.keys())}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAG Virtual Environment",
   "language": "python",
   "name": "nag-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
