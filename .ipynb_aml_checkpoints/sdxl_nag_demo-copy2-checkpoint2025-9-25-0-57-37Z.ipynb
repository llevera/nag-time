{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "67760698-b86d-4781-af28-dcadc05c711d"
      },
      "source": [
        "# Normalized Attention Guidance\n",
        "\n",
        "paper: https://arxiv.org/abs/2505.21179\n",
        "\n",
        "project page: https://chendaryen.github.io/NAG.github.io/\n",
        "\n",
        "Hugging Face Demo: https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-schnell and https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ffe50f-e3ef-4cf1-812d-38adf81451d3",
        "outputId": "cda6d190-6673-447e-c57b-a2081790ac35"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/ChenDarYen/Normalized-Attention-Guidance.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "260e2a657da947d498ea232d55bdaefe",
            "ffc7bba26eb24d3498e37395a9171488",
            "8076ac7669994de9ace9d6756425aa7a",
            "e00541ba92204863a373b74aaee442bc",
            "897734c1bdda475e9a31fcc02bd0fb57",
            "cb6268e4b30c4de3a2a5601456b7baea",
            "d9b2c6bd3a114d88b93d24f94016c865",
            "de495d8734c542e2b78556a128dd04ad",
            "f9c2cc67e7644a00a5e858ec79066bae",
            "fa20be7061f7454cbff87876fbaa35c9",
            "02375caec5d444f299978a07b7b0b239"
          ]
        },
        "gather": {
          "logged": 1760928102929
        },
        "id": "076473dc-d45f-494e-990b-ac7fe4af759a",
        "outputId": "96af804e-7d52-47a3-9eba-0cc0f2d3271e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "034161d2-31d5-4faa-87ec-d7e3f4db51ba",
      "metadata": {
        "gather": {
          "logged": 1760928026374
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "from diffusers import UNet2DConditionModel, LCMScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Add the workspace directory to sys.path\n",
        "workspace_dir = '/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance'\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo_name = \"tianweiy/DMD2\"\n",
        "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "\n",
        "unet = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(\"cuda\", torch.bfloat16)\n",
        "unet.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=\"cuda\"))\n",
        "pipe = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id,\n",
        "    unet=unet,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    variant=\"fp16\",\n",
        ").to(\"cuda\")\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "nag_negative_prompt = \"glasses, eyewear, spectacles\"\n",
        "\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    nag_negative_prompt=nag_negative_prompt,\n",
        "    guidance_scale=0,\n",
        "    nag_scale=3,\n",
        "    num_inference_steps=4,\n",
        ").images[0]\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845dc54f",
      "metadata": {
        "gather": {
          "logged": 1760933989791
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import UNet2DConditionModel, LCMScheduler, StableDiffusionXLPipeline\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.bfloat16\n",
        "\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo_name = \"tianweiy/DMD2\"\n",
        "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "\n",
        "# --- NAG pipeline (uses nag_negative_prompt + nag_scale) ---\n",
        "unet_nag = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(device, dtype)\n",
        "unet_nag.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=device))\n",
        "pipe_nag = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id, unet=unet_nag, torch_dtype=dtype, variant=\"fp16\"\n",
        ").to(device)\n",
        "pipe_nag.scheduler = LCMScheduler.from_config(pipe_nag.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "# --- Standard SDXL baseline (uses negative_prompt) ---\n",
        "pipe_std = StableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id, torch_dtype=dtype, variant=\"fp16\"\n",
        ").to(device)\n",
        "pipe_std.scheduler = LCMScheduler.from_config(pipe_std.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "block_glasses = \"glasses, eyewear, spectacles\"\n",
        "seeds = [2047, 2107]\n",
        "\n",
        "STEPS = 4\n",
        "LCM_CFG = 1.0      # good range for LCMs: ~0.8–1.5\n",
        "NAG_SCALE = 3.0    # 2–5 typically\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "\n",
        "    # 1) NAG, no NAG negatives (pure LCM sample)\n",
        "    img_nag_plain = pipe_nag(\n",
        "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 2) STD, no negatives (pure LCM sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_plain = pipe_std(\n",
        "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 3) NAG with NAG negatives (use nag_negative_prompt + nag_scale; CFG can be 0 or small)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_block = pipe_nag(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block_glasses,  # <-- NAG hook\n",
        "        nag_scale=NAG_SCALE,                # <-- strength\n",
        "        guidance_scale=0.0,                 # NAG usually run with CFG off\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    # 4) STD with normal negative_prompt (works, but weaker at 4 steps)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_block = pipe_std(\n",
        "        prompt,\n",
        "        negative_prompt=block_glasses,      # <-- standard CFG negative\n",
        "        guidance_scale=LCM_CFG,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_nag_plain, img_std_plain, img_nag_block, img_std_block])\n",
        "\n",
        "# Display the results as a grid\n",
        "# Create a comparison grid: 2 rows × 4 columns\n",
        "# Columns: NAG plain, STD plain, NAG block, STD block\n",
        "# Rows: Seed 1, Seed 2\n",
        "\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 2))\n",
        "\n",
        "# Place images in grid\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "# Display with labels\n",
        "print(\"Comparison Grid Layout:\")\n",
        "print(\"Column 1: NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]}\")\n",
        "grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "72c19e57",
      "metadata": {
        "gather": {
          "logged": 1761275527994
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/IPython/core/magics/basic.py:382: UserWarning: Error changing user exception modes.\n",
            "Unrecognized mode in FormattedTB: <Verbose     # richer tracebacks with locals>\n",
            "Valid modes: ['Plain', 'Context', 'Verbose', 'Minimal']\n",
            "  warn('Error changing %s exception modes.\\n%s' %\n",
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:01,  2.57it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.66it/s]\n",
            "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.57it/s]\n",
            "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.22it/s]\n",
            "100%|██████████| 4/4 [00:01<00:00,  2.03it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.98it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.67it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 12.95it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.23it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.63it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 12.84it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.54it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.22it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.83it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 13.32it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.15it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.62it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 13.45it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.48it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.05it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 13.09it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.13it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.76it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison Grid Layout (Impactful NAG; SDXL-Turbo, 4-step):\n",
            "Column 1: Impactful NAG (no negatives) | Column 2: STD (no negatives)\n",
            "Column 3: Impactful NAG + blocking     | Column 4: STD + blocking\n",
            "  nag_start=0.0, nag_ramp_steps=0, nag_end=1.0\n",
            "Row 1: Seed 2047 | Row 2: Seed 2107 | Row 3: Seed 2207 | Row 4: Seed 2307\n"
          ]
        }
      ],
      "source": [
        "# Impactful NAG (timed mid-window + attention-space normalisation)\n",
        "# Usage notes:\n",
        "#   - Use (nag_start, nag_end) ≈ (0.15, 0.40) for noun/object negatives; try (0.30, 0.55) for adjective/style negatives\n",
        "#   - For few-step samplers (1–4), prefer nag_scale in [3, 4], nag_tau≈2.5, nag_alpha≈0.25\n",
        "#   - nag_window_steps turns NAG off K iterations after it starts (small, surgical burst)\n",
        "%xmode verbose     # richer tracebacks with locals\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import (\n",
        "    UNet2DConditionModel,\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        ")\n",
        "\n",
        "# Add the workspace directory to sys.path (adjust if your project lives elsewhere)\n",
        "workspace_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance\"\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from nag import ImpactfulNAGStableDiffusionXLPipeline\n",
        "\n",
        "# ---------- Config ----------\n",
        "device = \"cuda\"\n",
        "weights_dtype = torch.bfloat16\n",
        "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "# Turbo UNet source\n",
        "turbo_repo = \"stabilityai/sdxl-turbo\"\n",
        "turbo_subfolder = \"unet\"\n",
        "\n",
        "# ---------- Base model (to borrow scheduler config) ----------\n",
        "base_pipe_for_cfg = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, torch_dtype=weights_dtype, use_safetensors=True\n",
        ")\n",
        "base_sched_config = base_pipe_for_cfg.scheduler.config\n",
        "del base_pipe_for_cfg  # keep VRAM tidy\n",
        "\n",
        "# ---------- SDXL-Turbo distilled UNet ----------\n",
        "distilled_unet = UNet2DConditionModel.from_pretrained(\n",
        "    turbo_repo, subfolder=turbo_subfolder, torch_dtype=weights_dtype, variant=\"fp16\"\n",
        ").to(device, weights_dtype)\n",
        "\n",
        "\n",
        "# ---------- Pipelines (EulerA for Turbo, trailing timesteps) ----------\n",
        "pipe_impactful_nag_turbo = ImpactfulNAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_impactful_nag_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ")\n",
        "\n",
        "pipe_std_turbo = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_std_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ") \n",
        "\n",
        "\n",
        "# ---------- Prompts, seeds, and settings ----------\n",
        "prompt = \"A bustling marketplace with vendors selling fresh fruits and vegetables\"\n",
        "block = \"glasses, eyewear\"\n",
        "seeds = [2047, 2107, 2207, 2307, 2407, 2507]\n",
        "\n",
        "STEPS = 4               # Turbo supports 1–4 steps; keep 4 to match your Lightning grid\n",
        "TURBO_CFG = 0.0         # ADD-style; typically run with CFG ~0\n",
        "\n",
        "# Impactful NAG timing parameters\n",
        "NAG_START = 0.0        # Delay NAG start to 20% of trajectory (for object deletion)\n",
        "                        # Try 0.30–0.40 for adjective/style negatives\n",
        "NAG_RAMP_STEPS = 0      # Leave at 0 unless quality dip; try 3 if needed\n",
        "NAG_SCALE = 3.0         # Standard NAG scale\n",
        "NAG_END = 1.0           # Default: keep NAG on to the end\n",
        "\n",
        "STD_BLOCKING_CFG = 1.0  # small CFG so negative_prompt has effect\n",
        "import pdb, sys, traceback\n",
        "\n",
        "try:\n",
        "\n",
        "    rows = []\n",
        "    for s in seeds:\n",
        "        # 1) Impactful NAG (Turbo UNet), no NAG negatives (pure Turbo sample)\n",
        "        g = torch.Generator(device=device).manual_seed(s)\n",
        "        img_impactful_1 = pipe_impactful_nag_turbo(\n",
        "            prompt, guidance_scale=TURBO_CFG, generator=g, num_inference_steps=STEPS\n",
        "        ).images[0]\n",
        "\n",
        "        g = torch.Generator(device=device).manual_seed(s)\n",
        "        img_impactful_2 = pipe_impactful_nag_turbo(\n",
        "            prompt,\n",
        "            nag_negative_prompt=block,\n",
        "            nag_scale=NAG_SCALE,\n",
        "            nag_start=0,\n",
        "            nag_ramp_steps=NAG_RAMP_STEPS,\n",
        "            nag_end=1,\n",
        "            nag_cooldown=0.08,                # configured…\n",
        "            nag_cooldown_cfg_drop=0.20,       # …but won’t change anything when CFG=0.0\n",
        "            guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
        "            num_inference_steps=STEPS,\n",
        "            generator=g,\n",
        "        ).images[0]\n",
        "\n",
        "        g = torch.Generator(device=device).manual_seed(s)\n",
        "        img_impactful_3 = pipe_impactful_nag_turbo(\n",
        "            prompt,\n",
        "            nag_negative_prompt=block,\n",
        "            nag_scale=NAG_SCALE,\n",
        "            nag_start=0.2,\n",
        "            nag_ramp_steps=NAG_RAMP_STEPS,\n",
        "            nag_end=0.8,\n",
        "            guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
        "            num_inference_steps=STEPS,\n",
        "            generator=g,\n",
        "        ).images[0]\n",
        "\n",
        "        g = torch.Generator(device=device).manual_seed(s)\n",
        "        img_impactful_4 = pipe_impactful_nag_turbo(\n",
        "            prompt,\n",
        "            nag_negative_prompt=block,\n",
        "            nag_scale=NAG_SCALE,\n",
        "            nag_start=0.2,\n",
        "            nag_ramp_steps=NAG_RAMP_STEPS,\n",
        "            nag_end=0.8,\n",
        "            nag_cooldown=0.08,                # configured…\n",
        "            nag_cooldown_cfg_drop=0.20,       # …but won’t change anything when CFG=0.0\n",
        "            guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
        "            num_inference_steps=STEPS,\n",
        "            generator=g,\n",
        "        ).images[0]\n",
        "\n",
        "        rows.append([img_impactful_1, img_impactful_2, img_impactful_3, img_impactful_4])\n",
        "\n",
        "except ZeroDivisionError:\n",
        "    traceback.print_exc()\n",
        "    pdb.post_mortem()\n",
        "# ---------- Assemble comparison grid (4 rows × 4 cols) ----------\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 6))\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "print(\"Comparison Grid Layout (Impactful NAG; SDXL-Turbo, 4-step):\")\n",
        "print(\"Column 1: Impactful NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: Impactful NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"  nag_start={NAG_START}, nag_ramp_steps={NAG_RAMP_STEPS}, nag_end={NAG_END}\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]} | Row 3: Seed {seeds[2]} | Row 4: Seed {seeds[3]}\")\n",
        "grid\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernel_info": {
      "name": "nag-venv"
    },
    "kernelspec": {
      "display_name": "NAG Virtual Environment",
      "language": "python",
      "name": "nag-venv"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
