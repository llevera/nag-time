{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "67760698-b86d-4781-af28-dcadc05c711d"
   },
   "source": [
    "# Normalized Attention Guidance\n",
    "\n",
    "paper: https://arxiv.org/abs/2505.21179\n",
    "\n",
    "project page: https://chendaryen.github.io/NAG.github.io/\n",
    "\n",
    "Hugging Face Demo: https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-schnell and https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48ffe50f-e3ef-4cf1-812d-38adf81451d3",
    "outputId": "cda6d190-6673-447e-c57b-a2081790ac35"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ChenDarYen/Normalized-Attention-Guidance.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "260e2a657da947d498ea232d55bdaefe",
      "ffc7bba26eb24d3498e37395a9171488",
      "8076ac7669994de9ace9d6756425aa7a",
      "e00541ba92204863a373b74aaee442bc",
      "897734c1bdda475e9a31fcc02bd0fb57",
      "cb6268e4b30c4de3a2a5601456b7baea",
      "d9b2c6bd3a114d88b93d24f94016c865",
      "de495d8734c542e2b78556a128dd04ad",
      "f9c2cc67e7644a00a5e858ec79066bae",
      "fa20be7061f7454cbff87876fbaa35c9",
      "02375caec5d444f299978a07b7b0b239"
     ]
    },
    "gather": {
     "logged": 1760928102929
    },
    "id": "076473dc-d45f-494e-990b-ac7fe4af759a",
    "outputId": "96af804e-7d52-47a3-9eba-0cc0f2d3271e"
   },
   "outputs": [],
   "source": [
    "\n",
    "from nag import NAGStableDiffusionXLPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034161d2-31d5-4faa-87ec-d7e3f4db51ba",
   "metadata": {
    "gather": {
     "logged": 1760928026374
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import UNet2DConditionModel, LCMScheduler\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Add the workspace directory to sys.path\n",
    "workspace_dir = '/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance'\n",
    "if workspace_dir not in sys.path:\n",
    "    sys.path.insert(0, workspace_dir)\n",
    "\n",
    "from nag import NAGStableDiffusionXLPipeline\n",
    "\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo_name = \"tianweiy/DMD2\"\n",
    "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
    "\n",
    "unet = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(\"cuda\", torch.bfloat16)\n",
    "unet.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=\"cuda\"))\n",
    "pipe = NAGStableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_id,\n",
    "    unet=unet,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    variant=\"fp16\",\n",
    ").to(\"cuda\")\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, original_inference_steps=4)\n",
    "\n",
    "prompt = \"A portrait of an older female librarian\"\n",
    "nag_negative_prompt = \"glasses, eyewear, spectacles\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    nag_negative_prompt=nag_negative_prompt,\n",
    "    guidance_scale=0,\n",
    "    nag_scale=3,\n",
    "    num_inference_steps=4,\n",
    ").images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845dc54f",
   "metadata": {
    "gather": {
     "logged": 1760933989791
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import UNet2DConditionModel, LCMScheduler, StableDiffusionXLPipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from nag import NAGStableDiffusionXLPipeline\n",
    "\n",
    "device = \"cuda\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo_name = \"tianweiy/DMD2\"\n",
    "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
    "\n",
    "# --- NAG pipeline (uses nag_negative_prompt + nag_scale) ---\n",
    "unet_nag = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(device, dtype)\n",
    "unet_nag.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=device))\n",
    "pipe_nag = NAGStableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_id, unet=unet_nag, torch_dtype=dtype, variant=\"fp16\"\n",
    ").to(device)\n",
    "pipe_nag.scheduler = LCMScheduler.from_config(pipe_nag.scheduler.config, original_inference_steps=4)\n",
    "\n",
    "# --- Standard SDXL baseline (uses negative_prompt) ---\n",
    "pipe_std = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_id, torch_dtype=dtype, variant=\"fp16\"\n",
    ").to(device)\n",
    "pipe_std.scheduler = LCMScheduler.from_config(pipe_std.scheduler.config, original_inference_steps=4)\n",
    "\n",
    "prompt = \"A portrait of an older female librarian\"\n",
    "block_glasses = \"glasses, eyewear, spectacles\"\n",
    "seeds = [2047, 2107]\n",
    "\n",
    "STEPS = 4\n",
    "LCM_CFG = 1.0      # good range for LCMs: ~0.8–1.5\n",
    "NAG_SCALE = 3.0    # 2–5 typically\n",
    "\n",
    "rows = []\n",
    "for s in seeds:\n",
    "    g = torch.Generator(device=device).manual_seed(s)\n",
    "\n",
    "    # 1) NAG, no NAG negatives (pure LCM sample)\n",
    "    img_nag_plain = pipe_nag(\n",
    "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
    "    ).images[0]\n",
    "\n",
    "    # 2) STD, no negatives (pure LCM sample)\n",
    "    g = torch.Generator(device=device).manual_seed(s)\n",
    "    img_std_plain = pipe_std(\n",
    "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
    "    ).images[0]\n",
    "\n",
    "    # 3) NAG with NAG negatives (use nag_negative_prompt + nag_scale; CFG can be 0 or small)\n",
    "    g = torch.Generator(device=device).manual_seed(s)\n",
    "    img_nag_block = pipe_nag(\n",
    "        prompt,\n",
    "        nag_negative_prompt=block_glasses,  # <-- NAG hook\n",
    "        nag_scale=NAG_SCALE,                # <-- strength\n",
    "        guidance_scale=0.0,                 # NAG usually run with CFG off\n",
    "        num_inference_steps=STEPS,\n",
    "        generator=g,\n",
    "    ).images[0]\n",
    "\n",
    "    # 4) STD with normal negative_prompt (works, but weaker at 4 steps)\n",
    "    g = torch.Generator(device=device).manual_seed(s)\n",
    "    img_std_block = pipe_std(\n",
    "        prompt,\n",
    "        negative_prompt=block_glasses,      # <-- standard CFG negative\n",
    "        guidance_scale=LCM_CFG,\n",
    "        num_inference_steps=STEPS,\n",
    "        generator=g,\n",
    "    ).images[0]\n",
    "\n",
    "    rows.append([img_nag_plain, img_std_plain, img_nag_block, img_std_block])\n",
    "\n",
    "# Display the results as a grid\n",
    "# Create a comparison grid: 2 rows × 4 columns\n",
    "# Columns: NAG plain, STD plain, NAG block, STD block\n",
    "# Rows: Seed 1, Seed 2\n",
    "\n",
    "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
    "grid = Image.new('RGB', (img_width * 4, img_height * 2))\n",
    "\n",
    "# Place images in grid\n",
    "for row_idx, row_images in enumerate(rows):\n",
    "    for col_idx, img in enumerate(row_images):\n",
    "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
    "\n",
    "# Display with labels\n",
    "print(\"Comparison Grid Layout:\")\n",
    "print(\"Column 1: NAG (no negatives) | Column 2: STD (no negatives)\")\n",
    "print(\"Column 3: NAG + blocking     | Column 4: STD + blocking\")\n",
    "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]}\")\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "72c19e57",
   "metadata": {
    "gather": {
     "logged": 1761360052995
    }
   },
   "outputs": [],
   "source": [
    "# Impactful NAG (timed mid-window + attention-space normalisation)\n",
    "# Usage notes:\n",
    "#   - Use (nag_start, nag_end) ≈ (0.15, 0.40) for noun/object negatives; try (0.30, 0.55) for adjective/style negatives\n",
    "#   - For few-step samplers (1–4), prefer nag_scale in [3, 4], nag_tau≈2.5, nag_alpha≈0.25\n",
    "#   - nag_window_steps turns NAG off K iterations after it starts (small, surgical burst)\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import (\n",
    "    UNet2DConditionModel,\n",
    "    StableDiffusionXLPipeline,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    ")\n",
    "\n",
    "# Add the workspace directory to sys.path (adjust if your project lives elsewhere)\n",
    "workspace_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance\"\n",
    "if workspace_dir not in sys.path:\n",
    "    sys.path.insert(0, workspace_dir)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nag import NAGTimeStableDiffusionXLPipeline\n",
    "\n",
    "# ---------- Config ----------\n",
    "device = \"cuda\"\n",
    "weights_dtype = torch.bfloat16\n",
    "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "# Turbo UNet source\n",
    "turbo_repo = \"stabilityai/sdxl-turbo\"\n",
    "turbo_subfolder = \"unet\"\n",
    "\n",
    "# ---------- Base model (to borrow scheduler config) ----------\n",
    "base_pipe_for_cfg = StableDiffusionXLPipeline.from_pretrained(\n",
    "    basemodel_id, torch_dtype=weights_dtype, use_safetensors=True\n",
    ")\n",
    "base_sched_config = base_pipe_for_cfg.scheduler.config\n",
    "del base_pipe_for_cfg  # keep VRAM tidy\n",
    "\n",
    "# ---------- SDXL-Turbo distilled UNet ----------\n",
    "distilled_unet = UNet2DConditionModel.from_pretrained(\n",
    "    turbo_repo, subfolder=turbo_subfolder, torch_dtype=weights_dtype, variant=\"fp16\"\n",
    ").to(device, weights_dtype)\n",
    "\n",
    "\n",
    "# ---------- Pipelines (EulerA for Turbo, trailing timesteps) ----------\n",
    "pipe_impactful_nag_turbo = NAGTimeStableDiffusionXLPipeline.from_pretrained(\n",
    "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
    ").to(device)\n",
    "pipe_impactful_nag_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
    "    base_sched_config, timestep_spacing=\"trailing\"\n",
    ")\n",
    "\n",
    "pipe_std_turbo = StableDiffusionXLPipeline.from_pretrained(\n",
    "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
    ").to(device)\n",
    "pipe_std_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
    "    base_sched_config, timestep_spacing=\"trailing\"\n",
    ") \n",
    "\n",
    "\n",
    "# ---------- Prompts, seeds, and settings ----------\n",
    "prompt = \"A portrait of an older female librarian\"\n",
    "block = \"glasses\"\n",
    "seeds = [2047, 2107, 2207, 2307, 2407, 2507]\n",
    "\n",
    "STEPS = 4               # Turbo supports 1–4 steps; keep 4 to match your Lightning grid\n",
    "TURBO_CFG = 0.0         # ADD-style; typically run with CFG ~0\n",
    "\n",
    "# Impactful NAG timing parameters\n",
    "NAG_START = 0.0        # Delay NAG start to 20% of trajectory (for object deletion)\n",
    "                        # Try 0.30–0.40 for adjective/style negatives\n",
    "NAG_RAMP_STEPS = 0      # Leave at 0 unless quality dip; try 3 if needed\n",
    "NAG_SCALE = 3.0         # Standard NAG scale\n",
    "NAG_END = 1.0           # Default: keep NAG on to the end\n",
    "\n",
    "STD_BLOCKING_CFG = 1.0  # small CFG so negative_prompt has effect\n",
    "import pdb, sys, traceback\n",
    "\n",
    "try:\n",
    "\n",
    "    rows = []\n",
    "    for s in seeds:\n",
    "        # 1) Impactful NAG (Turbo UNet), no NAG negatives (pure Turbo sample)\n",
    "        g = torch.Generator(device=device).manual_seed(s)\n",
    "        img_impactful_1 = pipe_impactful_nag_turbo(\n",
    "            prompt, guidance_scale=TURBO_CFG, generator=g, num_inference_steps=STEPS\n",
    "        ).images[0]\n",
    "\n",
    "        g = torch.Generator(device=device).manual_seed(s)\n",
    "        img_impactful_2 = pipe_impactful_nag_turbo(\n",
    "            prompt,\n",
    "            nag_negative_prompt=block,\n",
    "            nag_scale=NAG_SCALE,\n",
    "            nag_start=0,\n",
    "            nag_ramp_steps=NAG_RAMP_STEPS,\n",
    "            nag_end=1,\n",
    "            nag_cooldown=0.08,                # configured…\n",
    "            nag_cooldown_cfg_drop=0.20,       # …but won’t change anything when CFG=0.0\n",
    "            guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
    "            num_inference_steps=STEPS,\n",
    "            generator=g,\n",
    "        ).images[0]\n",
    "\n",
    "        g = torch.Generator(device=device).manual_seed(s)\n",
    "        img_impactful_3 = pipe_impactful_nag_turbo(\n",
    "            prompt,\n",
    "            nag_negative_prompt=block,\n",
    "            nag_scale=NAG_SCALE,\n",
    "            nag_start=0.2,\n",
    "            nag_ramp_steps=NAG_RAMP_STEPS,\n",
    "            nag_end=0.8,\n",
    "            guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
    "            num_inference_steps=STEPS,\n",
    "            generator=g,\n",
    "        ).images[0]\n",
    "\n",
    "        g = torch.Generator(device=device).manual_seed(s)\n",
    "        img_impactful_4 = pipe_impactful_nag_turbo(\n",
    "            prompt,\n",
    "            nag_negative_prompt=block,\n",
    "            nag_scale=NAG_SCALE,\n",
    "            nag_start=0.2,\n",
    "            nag_ramp_steps=NAG_RAMP_STEPS,\n",
    "            nag_end=0.8,\n",
    "            nag_cooldown=0.08,                # configured…\n",
    "            nag_cooldown_cfg_drop=0.20,       # …but won’t change anything when CFG=0.0\n",
    "            guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
    "            num_inference_steps=STEPS,\n",
    "            generator=g,\n",
    "        ).images[0]\n",
    "\n",
    "        rows.append([img_impactful_1, img_impactful_2, img_impactful_3, img_impactful_4])\n",
    "\n",
    "except ZeroDivisionError:\n",
    "    traceback.print_exc()\n",
    "    pdb.post_mortem()\n",
    "# ---------- Assemble comparison grid (4 rows × 4 cols) ----------\n",
    "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
    "grid = Image.new('RGB', (img_width * 4, img_height * 6))\n",
    "for row_idx, row_images in enumerate(rows):\n",
    "    for col_idx, img in enumerate(row_images):\n",
    "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
    "\n",
    "print(\"Comparison Grid Layout (Impactful NAG; SDXL-Turbo, 4-step):\")\n",
    "print(\"Column 1: Impactful NAG (no negatives) | Column 2: STD (no negatives)\")\n",
    "print(\"Column 3: Impactful NAG + blocking     | Column 4: STD + blocking\")\n",
    "print(f\"  nag_start={NAG_START}, nag_ramp_steps={NAG_RAMP_STEPS}, nag_end={NAG_END}\")\n",
    "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]} | Row 3: Seed {seeds[2]} | Row 4: Seed {seeds[3]}\")\n",
    "grid\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernel_info": {
   "name": "nag-venv"
  },
  "kernelspec": {
   "display_name": "NAG (Python 3.13)",
   "language": "python",
   "name": "nag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
