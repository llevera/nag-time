{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Normalized Attention Guidance\n",
        "\n",
        "paper: https://arxiv.org/abs/2505.21179\n",
        "\n",
        "project page: https://chendaryen.github.io/NAG.github.io/\n",
        "\n",
        "Hugging Face Demo: https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-schnell and https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-dev"
      ],
      "metadata": {
        "id": "67760698-b86d-4781-af28-dcadc05c711d"
      },
      "id": "0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ChenDarYen/Normalized-Attention-Guidance.git"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ffe50f-e3ef-4cf1-812d-38adf81451d3",
        "outputId": "cda6d190-6673-447e-c57b-a2081790ac35"
      },
      "id": "1"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "260e2a657da947d498ea232d55bdaefe",
            "ffc7bba26eb24d3498e37395a9171488",
            "8076ac7669994de9ace9d6756425aa7a",
            "e00541ba92204863a373b74aaee442bc",
            "897734c1bdda475e9a31fcc02bd0fb57",
            "cb6268e4b30c4de3a2a5601456b7baea",
            "d9b2c6bd3a114d88b93d24f94016c865",
            "de495d8734c542e2b78556a128dd04ad",
            "f9c2cc67e7644a00a5e858ec79066bae",
            "fa20be7061f7454cbff87876fbaa35c9",
            "02375caec5d444f299978a07b7b0b239"
          ]
        },
        "gather": {
          "logged": 1760928102929
        },
        "id": "076473dc-d45f-494e-990b-ac7fe4af759a",
        "outputId": "96af804e-7d52-47a3-9eba-0cc0f2d3271e"
      },
      "id": "2"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "from diffusers import UNet2DConditionModel, LCMScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Add the workspace directory to sys.path\n",
        "workspace_dir = '/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance'\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo_name = \"tianweiy/DMD2\"\n",
        "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "\n",
        "unet = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(\"cuda\", torch.bfloat16)\n",
        "unet.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=\"cuda\"))\n",
        "pipe = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id,\n",
        "    unet=unet,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    variant=\"fp16\",\n",
        ").to(\"cuda\")\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "nag_negative_prompt = \"glasses, eyewear, spectacles\"\n",
        "\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    nag_negative_prompt=nag_negative_prompt,\n",
        "    guidance_scale=0,\n",
        "    nag_scale=3,\n",
        "    num_inference_steps=4,\n",
        ").images[0]\n",
        "\n",
        "image"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1760928026374
        }
      },
      "id": "034161d2-31d5-4faa-87ec-d7e3f4db51ba"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import UNet2DConditionModel, LCMScheduler, StableDiffusionXLPipeline\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.bfloat16\n",
        "\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo_name = \"tianweiy/DMD2\"\n",
        "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "\n",
        "# --- NAG pipeline (uses nag_negative_prompt + nag_scale) ---\n",
        "unet_nag = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(device, dtype)\n",
        "unet_nag.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=device))\n",
        "pipe_nag = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id, unet=unet_nag, torch_dtype=dtype, variant=\"fp16\"\n",
        ").to(device)\n",
        "pipe_nag.scheduler = LCMScheduler.from_config(pipe_nag.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "# --- Standard SDXL baseline (uses negative_prompt) ---\n",
        "pipe_std = StableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id, torch_dtype=dtype, variant=\"fp16\"\n",
        ").to(device)\n",
        "pipe_std.scheduler = LCMScheduler.from_config(pipe_std.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "block_glasses = \"glasses, eyewear, spectacles\"\n",
        "seeds = [2047, 2107]\n",
        "\n",
        "STEPS = 4\n",
        "LCM_CFG = 1.0      # good range for LCMs: ~0.8–1.5\n",
        "NAG_SCALE = 3.0    # 2–5 typically\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "\n",
        "    # 1) NAG, no NAG negatives (pure LCM sample)\n",
        "    img_nag_plain = pipe_nag(\n",
        "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 2) STD, no negatives (pure LCM sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_plain = pipe_std(\n",
        "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 3) NAG with NAG negatives (use nag_negative_prompt + nag_scale; CFG can be 0 or small)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_block = pipe_nag(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block_glasses,  # <-- NAG hook\n",
        "        nag_scale=NAG_SCALE,                # <-- strength\n",
        "        guidance_scale=0.0,                 # NAG usually run with CFG off\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    # 4) STD with normal negative_prompt (works, but weaker at 4 steps)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_block = pipe_std(\n",
        "        prompt,\n",
        "        negative_prompt=block_glasses,      # <-- standard CFG negative\n",
        "        guidance_scale=LCM_CFG,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_nag_plain, img_std_plain, img_nag_block, img_std_block])\n",
        "\n",
        "# Display the results as a grid\n",
        "# Create a comparison grid: 2 rows × 4 columns\n",
        "# Columns: NAG plain, STD plain, NAG block, STD block\n",
        "# Rows: Seed 1, Seed 2\n",
        "\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 2))\n",
        "\n",
        "# Place images in grid\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "# Display with labels\n",
        "print(\"Comparison Grid Layout:\")\n",
        "print(\"Column 1: NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]}\")\n",
        "grid"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1760933989791
        }
      },
      "id": "845dc54f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Impactful NAG (timed mid-window + attention-space normalisation)\n",
        "# Usage notes:\n",
        "#   - Use (nag_start, nag_end) ≈ (0.15, 0.40) for noun/object negatives; try (0.30, 0.55) for adjective/style negatives\n",
        "#   - For few-step samplers (1–4), prefer nag_scale in [3, 4], nag_tau≈2.5, nag_alpha≈0.25\n",
        "#   - nag_window_steps turns NAG off K iterations after it starts (small, surgical burst)\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import (\n",
        "    UNet2DConditionModel,\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        ")\n",
        "\n",
        "# Add the workspace directory to sys.path (adjust if your project lives elsewhere)\n",
        "workspace_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance\"\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from nag import ImpactfulNAGStableDiffusionXLPipeline\n",
        "\n",
        "# ---------- Config ----------\n",
        "device = \"cuda\"\n",
        "weights_dtype = torch.bfloat16\n",
        "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "# Turbo UNet source\n",
        "turbo_repo = \"stabilityai/sdxl-turbo\"\n",
        "turbo_subfolder = \"unet\"\n",
        "\n",
        "# ---------- Base model (to borrow scheduler config) ----------\n",
        "base_pipe_for_cfg = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, torch_dtype=weights_dtype, use_safetensors=True\n",
        ")\n",
        "base_sched_config = base_pipe_for_cfg.scheduler.config\n",
        "del base_pipe_for_cfg  # keep VRAM tidy\n",
        "\n",
        "# ---------- SDXL-Turbo distilled UNet ----------\n",
        "distilled_unet = UNet2DConditionModel.from_pretrained(\n",
        "    turbo_repo, subfolder=turbo_subfolder, torch_dtype=weights_dtype, variant=\"fp16\"\n",
        ").to(device, weights_dtype)\n",
        "\n",
        "\n",
        "# ---------- Pipelines (EulerA for Turbo, trailing timesteps) ----------\n",
        "pipe_impactful_nag_turbo = ImpactfulNAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_impactful_nag_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ")\n",
        "\n",
        "pipe_std_turbo = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_std_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ") \n",
        "\n",
        "\n",
        "# ---------- Prompts, seeds, and settings ----------\n",
        "prompt = \"An older female librarian\"\n",
        "block = \"glasses, eyewear\"\n",
        "seeds = [2047, 2107, 2207, 2307, 2407, 2507]\n",
        "\n",
        "STEPS = 4               # Turbo supports 1–4 steps; keep 4 to match your Lightning grid\n",
        "TURBO_CFG = 0.0         # ADD-style; typically run with CFG ~0\n",
        "\n",
        "# Impactful NAG timing parameters\n",
        "NAG_START = 0.0        # Delay NAG start to 20% of trajectory (for object deletion)\n",
        "                        # Try 0.30–0.40 for adjective/style negatives\n",
        "NAG_RAMP_STEPS = 0      # Leave at 0 unless quality dip; try 3 if needed\n",
        "NAG_SCALE = 3.0         # Standard NAG scale\n",
        "NAG_END = 1.0           # Default: keep NAG on to the end\n",
        "\n",
        "STD_BLOCKING_CFG = 1.0  # small CFG so negative_prompt has effect\n",
        "\n",
        "\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    # 1) Impactful NAG (Turbo UNet), no NAG negatives (pure Turbo sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_impactful_1 = pipe_impactful_nag_turbo(\n",
        "        prompt, guidance_scale=TURBO_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_impactful_2 = pipe_impactful_nag_turbo(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block,\n",
        "        nag_scale=NAG_SCALE,\n",
        "        nag_start=0,\n",
        "        nag_ramp_steps=NAG_RAMP_STEPS,\n",
        "        nag_end=1,\n",
        "        nag_cooldown=0.08,                # configured…\n",
        "        nag_cooldown_cfg_drop=0.20,       # …but won’t change anything when CFG=0.0\n",
        "        guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_impactful_3 = pipe_impactful_nag_turbo(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block,\n",
        "        nag_scale=NAG_SCALE,\n",
        "        nag_start=0.3,\n",
        "        nag_ramp_steps=NAG_RAMP_STEPS,\n",
        "        nag_end=0.8,\n",
        "        guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_impactful_4 = pipe_impactful_nag_turbo(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block,\n",
        "        nag_scale=NAG_SCALE,\n",
        "        nag_start=0.3,\n",
        "        nag_ramp_steps=NAG_RAMP_STEPS,\n",
        "        nag_end=0.8,\n",
        "        nag_cooldown=0.08,                # configured…\n",
        "        nag_cooldown_cfg_drop=0.20,       # …but won’t change anything when CFG=0.0\n",
        "        guidance_scale=0.0,               # <- this nullifies the cool-down effect\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_impactful_1, img_impactful_2, img_impactful_3, img_impactful_4])\n",
        "\n",
        "# ---------- Assemble comparison grid (4 rows × 4 cols) ----------\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 6))\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "print(\"Comparison Grid Layout (Impactful NAG; SDXL-Turbo, 4-step):\")\n",
        "print(\"Column 1: Impactful NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: Impactful NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"  nag_start={NAG_START}, nag_ramp_steps={NAG_RAMP_STEPS}, nag_end={NAG_END}\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]} | Row 3: Seed {seeds[2]} | Row 4: Seed {seeds[3]}\")\n",
        "grid\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  3.69it/s]\nLoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.64it/s]\nLoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.36it/s]\n100%|██████████| 4/4 [00:00<00:00, 13.80it/s]\n  0%|          | 0/4 [00:00<?, ?it/s]\n"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 96\u001b[0m\n\u001b[1;32m     91\u001b[0m img_impactful_1 \u001b[38;5;241m=\u001b[39m pipe_impactful_nag_turbo(\n\u001b[1;32m     92\u001b[0m     prompt, guidance_scale\u001b[38;5;241m=\u001b[39mTURBO_CFG, generator\u001b[38;5;241m=\u001b[39mg, num_inference_steps\u001b[38;5;241m=\u001b[39mSTEPS\n\u001b[1;32m     93\u001b[0m )\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     95\u001b[0m g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator(device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mmanual_seed(s)\n\u001b[0;32m---> 96\u001b[0m img_impactful_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpipe_impactful_nag_turbo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_negative_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNAG_SCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_ramp_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNAG_RAMP_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_cooldown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.08\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# configured…\u001b[39;49;00m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnag_cooldown_cfg_drop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# …but won’t change anything when CFG=0.0\u001b[39;49;00m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# <- this nullifies the cool-down effect\u001b[39;49;00m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    110\u001b[0m g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator(device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mmanual_seed(s)\n\u001b[1;32m    111\u001b[0m img_impactful_3 \u001b[38;5;241m=\u001b[39m pipe_impactful_nag_turbo(\n\u001b[1;32m    112\u001b[0m     prompt,\n\u001b[1;32m    113\u001b[0m     nag_negative_prompt\u001b[38;5;241m=\u001b[39mblock,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     generator\u001b[38;5;241m=\u001b[39mg,\n\u001b[1;32m    121\u001b[0m )\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/cloudfiles/code/Users/Normalized-Attention-Guidance/nag/pipeline_sdxl_impactful_nag.py:462\u001b[0m, in \u001b[0;36mImpactfulNAGStableDiffusionXLPipeline.__call__\u001b[0;34m(self, prompt, prompt_2, height, width, num_inference_steps, timesteps, sigmas, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, nag_scale, nag_tau, nag_alpha, nag_negative_prompt, nag_negative_prompt_embeds, nag_negative_pooled_prompt_embeds, nag_end, nag_start, nag_ramp_steps, nag_cooldown, nag_cooldown_cfg_drop, neutralize_with_negative, neutralize_strength, neutralize_window, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# 1-branch\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     latent_model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mscale_model_input(latents, t)\n\u001b[0;32m--> 462\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_prompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_embeds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_text_embeds_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_time_ids\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    471\u001b[0m     ref_text \u001b[38;5;241m=\u001b[39m noise_pred  \u001b[38;5;66;03m# dummy\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# Optional rescale\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/models/unets/unet_2d_condition.py:1215\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_adapter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(down_intrablock_additional_residuals) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1213\u001b[0m         additional_residuals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_residuals\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m down_intrablock_additional_residuals\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1215\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m \u001b[43mdownsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     sample, res_samples \u001b[38;5;241m=\u001b[39m downsample_block(hidden_states\u001b[38;5;241m=\u001b[39msample, temb\u001b[38;5;241m=\u001b[39memb)\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/models/unets/unet_2d_blocks.py:1270\u001b[0m, in \u001b[0;36mCrossAttnDownBlock2D.forward\u001b[0;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask, additional_residuals)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1269\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m resnet(hidden_states, temb)\n\u001b[0;32m-> 1270\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;66;03m# apply additional residuals to the output of the last pair of resnet and attention blocks\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m additional_residuals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:427\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    416\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    417\u001b[0m             block,\n\u001b[1;32m    418\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m             class_labels,\n\u001b[1;32m    425\u001b[0m         )\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# 3. Output\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_input_continuous:\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/models/attention.py:1033\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mada_norm_single\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1031\u001b[0m         norm_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed(norm_hidden_states)\n\u001b[0;32m-> 1033\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 4. Feed-forward\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# i2vgen doesn't have this norm 🤷‍♂️\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/a100-ml/code/Users/Normalized-Attention-Guidance/.venv/lib/python3.10/site-packages/diffusers/models/attention_processor.py:605\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, attention_mask, **cross_attention_kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_attention_kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not expected by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m     )\n\u001b[1;32m    603\u001b[0m cross_attention_kwargs \u001b[38;5;241m=\u001b[39m {k: w \u001b[38;5;28;01mfor\u001b[39;00m k, w \u001b[38;5;129;01min\u001b[39;00m cross_attention_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m attn_parameters}\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/cloudfiles/code/Users/Normalized-Attention-Guidance/nag/attention_nag.py:49\u001b[0m, in \u001b[0;36mNAGAttnProcessor2_0.__call__\u001b[0;34m(self, attn, hidden_states, encoder_hidden_states, attention_mask, temb, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_guidance:\n\u001b[1;32m     48\u001b[0m     origin_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(hidden_states)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43morigin_batch_size\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39mprepare_attention_mask(attention_mask, sequence_length, batch_size)\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1761262643411
        }
      },
      "id": "72c19e57"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernel_info": {
      "name": "nag-venv"
    },
    "kernelspec": {
      "name": "nag-venv",
      "language": "python",
      "display_name": "NAG Virtual Environment"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}