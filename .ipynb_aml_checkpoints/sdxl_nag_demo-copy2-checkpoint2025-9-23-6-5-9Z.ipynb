{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Normalized Attention Guidance\n",
        "\n",
        "paper: https://arxiv.org/abs/2505.21179\n",
        "\n",
        "project page: https://chendaryen.github.io/NAG.github.io/\n",
        "\n",
        "Hugging Face Demo: https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-schnell and https://huggingface.co/spaces/ChenDY/NAG_FLUX.1-dev"
      ],
      "metadata": {
        "id": "67760698-b86d-4781-af28-dcadc05c711d"
      },
      "id": "0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ChenDarYen/Normalized-Attention-Guidance.git"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ffe50f-e3ef-4cf1-812d-38adf81451d3",
        "outputId": "cda6d190-6673-447e-c57b-a2081790ac35"
      },
      "id": "1"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "260e2a657da947d498ea232d55bdaefe",
            "ffc7bba26eb24d3498e37395a9171488",
            "8076ac7669994de9ace9d6756425aa7a",
            "e00541ba92204863a373b74aaee442bc",
            "897734c1bdda475e9a31fcc02bd0fb57",
            "cb6268e4b30c4de3a2a5601456b7baea",
            "d9b2c6bd3a114d88b93d24f94016c865",
            "de495d8734c542e2b78556a128dd04ad",
            "f9c2cc67e7644a00a5e858ec79066bae",
            "fa20be7061f7454cbff87876fbaa35c9",
            "02375caec5d444f299978a07b7b0b239"
          ]
        },
        "gather": {
          "logged": 1760928102929
        },
        "id": "076473dc-d45f-494e-990b-ac7fe4af759a",
        "outputId": "96af804e-7d52-47a3-9eba-0cc0f2d3271e"
      },
      "id": "2"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "from diffusers import UNet2DConditionModel, LCMScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Add the workspace directory to sys.path\n",
        "workspace_dir = '/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance'\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo_name = \"tianweiy/DMD2\"\n",
        "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "\n",
        "unet = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(\"cuda\", torch.bfloat16)\n",
        "unet.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=\"cuda\"))\n",
        "pipe = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id,\n",
        "    unet=unet,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    variant=\"fp16\",\n",
        ").to(\"cuda\")\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "nag_negative_prompt = \"glasses, eyewear, spectacles\"\n",
        "\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    nag_negative_prompt=nag_negative_prompt,\n",
        "    guidance_scale=0,\n",
        "    nag_scale=3,\n",
        "    num_inference_steps=4,\n",
        ").images[0]\n",
        "\n",
        "image"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1760928026374
        }
      },
      "id": "034161d2-31d5-4faa-87ec-d7e3f4db51ba"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import UNet2DConditionModel, LCMScheduler, StableDiffusionXLPipeline\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "device = \"cuda\"\n",
        "dtype = torch.bfloat16\n",
        "\n",
        "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo_name = \"tianweiy/DMD2\"\n",
        "ckpt_name = \"dmd2_sdxl_4step_unet_fp16.bin\"\n",
        "\n",
        "# --- NAG pipeline (uses nag_negative_prompt + nag_scale) ---\n",
        "unet_nag = UNet2DConditionModel.from_config(base_model_id, subfolder=\"unet\").to(device, dtype)\n",
        "unet_nag.load_state_dict(torch.load(hf_hub_download(repo_name, ckpt_name), map_location=device))\n",
        "pipe_nag = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id, unet=unet_nag, torch_dtype=dtype, variant=\"fp16\"\n",
        ").to(device)\n",
        "pipe_nag.scheduler = LCMScheduler.from_config(pipe_nag.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "# --- Standard SDXL baseline (uses negative_prompt) ---\n",
        "pipe_std = StableDiffusionXLPipeline.from_pretrained(\n",
        "    base_model_id, torch_dtype=dtype, variant=\"fp16\"\n",
        ").to(device)\n",
        "pipe_std.scheduler = LCMScheduler.from_config(pipe_std.scheduler.config, original_inference_steps=4)\n",
        "\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "block_glasses = \"glasses, eyewear, spectacles\"\n",
        "seeds = [2047, 2107]\n",
        "\n",
        "STEPS = 4\n",
        "LCM_CFG = 1.0      # good range for LCMs: ~0.8–1.5\n",
        "NAG_SCALE = 3.0    # 2–5 typically\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "\n",
        "    # 1) NAG, no NAG negatives (pure LCM sample)\n",
        "    img_nag_plain = pipe_nag(\n",
        "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 2) STD, no negatives (pure LCM sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_plain = pipe_std(\n",
        "        prompt, guidance_scale=LCM_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 3) NAG with NAG negatives (use nag_negative_prompt + nag_scale; CFG can be 0 or small)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_block = pipe_nag(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block_glasses,  # <-- NAG hook\n",
        "        nag_scale=NAG_SCALE,                # <-- strength\n",
        "        guidance_scale=0.0,                 # NAG usually run with CFG off\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    # 4) STD with normal negative_prompt (works, but weaker at 4 steps)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_block = pipe_std(\n",
        "        prompt,\n",
        "        negative_prompt=block_glasses,      # <-- standard CFG negative\n",
        "        guidance_scale=LCM_CFG,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_nag_plain, img_std_plain, img_nag_block, img_std_block])\n",
        "\n",
        "# Display the results as a grid\n",
        "# Create a comparison grid: 2 rows × 4 columns\n",
        "# Columns: NAG plain, STD plain, NAG block, STD block\n",
        "# Rows: Seed 1, Seed 2\n",
        "\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 2))\n",
        "\n",
        "# Place images in grid\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "# Display with labels\n",
        "print(\"Comparison Grid Layout:\")\n",
        "print(\"Column 1: NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]}\")\n",
        "grid"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1760933989791
        }
      },
      "id": "845dc54f"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import (\n",
        "    UNet2DConditionModel,\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerDiscreteScheduler,\n",
        ")\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "from nag import NAGStableDiffusionXLPipeline\n",
        "\n",
        "# ---------- Config ----------\n",
        "device = \"cuda\"\n",
        "weights_dtype = torch.bfloat16\n",
        "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "# Lightning (4-step) distilled UNet\n",
        "lightning_repo = \"ByteDance/SDXL-Lightning\"\n",
        "lightning_ckpt = \"sdxl_lightning_4step_unet.safetensors\"  # ensure this matches your intended steps\n",
        "\n",
        "# ---------- Base model & Euler scheduler ----------\n",
        "base_unet = UNet2DConditionModel.from_pretrained(\n",
        "    basemodel_id, subfolder=\"unet\"\n",
        ").to(device, weights_dtype)\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=base_unet, torch_dtype=weights_dtype, use_safetensors=True\n",
        ").to(device)\n",
        "\n",
        "# Make the base scheduler Euler as well\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "base_scheduler = pipe.scheduler  # kept for reference/consistency\n",
        "\n",
        "# ---------- SDXL-Lightning distilled UNet ----------\n",
        "distilled_unet = UNet2DConditionModel.from_config(  # typo fixed below (UNet2DConditionModel)\n",
        "    basemodel_id, subfolder=\"unet\"\n",
        ").to(device, weights_dtype)\n",
        "distilled_unet.load_state_dict(load_file(hf_hub_download(lightning_repo, lightning_ckpt), device=device))\n",
        "\n",
        "# ---------- NAG & STD pipelines (both Euler, trailing) ----------\n",
        "pipe_nag = NAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_nag.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "\n",
        "pipe_std = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_std.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "\n",
        "# ---------- Prompts, seeds, and settings ----------\n",
        "prompt = \"A portrait of an older female librarian\"\n",
        "block_glasses = \"glasses, eyewear, spectacles\"\n",
        "seeds = [2047, 2107, 2207, 2307]\n",
        "\n",
        "STEPS = 4                 # matches 4-step Lightning ckpt\n",
        "LIGHTNING_CFG = 0.0       # Lightning is typically run with CFG ~0\n",
        "NAG_SCALE = 3.0           # 2–5 typical\n",
        "STD_BLOCKING_CFG = 1.0    # small CFG so negative_prompt has effect\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    # 1) NAG (Lightning UNet), no NAG negatives (pure Lightning sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_plain = pipe_nag(\n",
        "        prompt, guidance_scale=LIGHTNING_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 2) STD (Lightning UNet), no negatives (pure Lightning sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_plain = pipe_std(\n",
        "        prompt, guidance_scale=LIGHTNING_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 3) NAG with NAG negatives (CFG off)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_block = pipe_nag(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block_glasses,\n",
        "        nag_scale=NAG_SCALE,\n",
        "        guidance_scale=0.0,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    # 4) STD with normal negative_prompt (small CFG so it bites a little)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_block = pipe_std(\n",
        "        prompt,\n",
        "        negative_prompt=block_glasses,\n",
        "        guidance_scale=STD_BLOCKING_CFG,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_nag_plain, img_std_plain, img_nag_block, img_std_block])\n",
        "\n",
        "# ---------- Assemble comparison grid (2 rows × 4 cols) ----------\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 4))\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "print(\"Comparison Grid Layout (Euler everywhere; SDXL-Lightning 4-step):\")\n",
        "print(\"Column 1: NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]} | Row 3: Seed {seeds[2]} | Row 4: Seed {seeds[3]}\")\n",
        "grid\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1760934547002
        }
      },
      "id": "f813aced"
    },
    {
      "cell_type": "code",
      "source": [
        "# Impactful NAG: timed variant with soft-start and end control\n",
        "# Usage notes:\n",
        "#   - Start with nag_start=0.17–0.25 for object deletion; 0.30–0.40 for adjective/style negatives\n",
        "#   - Leave nag_ramp_steps=0 unless you see a small quality dip right after the start; then try nag_ramp_steps=3\n",
        "#   - Your existing nag_end keeps working; default 1.0 means \"keep NAG on to the end\"\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "from PIL import Image\n",
        "from diffusers import (\n",
        "    UNet2DConditionModel,\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        ")\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "# Add the workspace directory to sys.path\n",
        "workspace_dir = '/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance'\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "\n",
        "from nag import ImpactfulNAGStableDiffusionXLPipeline\n",
        "\n",
        "# ---------- Config ----------\n",
        "device = \"cuda\"\n",
        "weights_dtype = torch.bfloat16\n",
        "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "# Turbo UNet source\n",
        "turbo_repo = \"stabilityai/sdxl-turbo\"\n",
        "turbo_subfolder = \"unet\"\n",
        "\n",
        "# ---------- Base model (to borrow scheduler config) ----------\n",
        "base_pipe_for_cfg = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, torch_dtype=weights_dtype, use_safetensors=True\n",
        ")\n",
        "base_sched_config = base_pipe_for_cfg.scheduler.config\n",
        "del base_pipe_for_cfg  # keep VRAM tidy\n",
        "\n",
        "# ---------- SDXL-Turbo distilled UNet ----------\n",
        "distilled_unet = UNet2DConditionModel.from_pretrained(\n",
        "    turbo_repo, subfolder=turbo_subfolder, torch_dtype=weights_dtype, variant=\"fp16\"\n",
        ").to(device, weights_dtype)\n",
        "\n",
        "# ---------- Pipelines (EulerA for Turbo, trailing timesteps) ----------\n",
        "pipe_impactful_nag_turbo = ImpactfulNAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_impactful_nag_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ")\n",
        "\n",
        "pipe_std_turbo = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_std_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ") \n",
        "\n",
        "# ---------- Prompts, seeds, and settings ----------\n",
        "prompt = \"Hipster coffee shop worker\"\n",
        "block_glasses = \"beard, stubble\"\n",
        "seeds = [2047, 2107, 2207, 2307, 2407, 2507]\n",
        "\n",
        "STEPS = 4               # Turbo supports 1–4 steps; keep 4 to match your Lightning grid\n",
        "TURBO_CFG = 0.0         # ADD-style; typically run with CFG ~0\n",
        "\n",
        "# Impactful NAG timing parameters\n",
        "NAG_START = 0.20        # Delay NAG start to 20% of trajectory (for object deletion)\n",
        "                        # Try 0.30–0.40 for adjective/style negatives\n",
        "NAG_RAMP_STEPS = 0      # Leave at 0 unless quality dip; try 3 if needed\n",
        "NAG_SCALE = 3.0         # Standard NAG scale\n",
        "NAG_END = 1.0           # Default: keep NAG on to the end\n",
        "\n",
        "STD_BLOCKING_CFG = 1.0  # small CFG so negative_prompt has effect\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    # 1) Impactful NAG (Turbo UNet), no NAG negatives (pure Turbo sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_impactful_plain = pipe_impactful_nag_turbo(\n",
        "        prompt, guidance_scale=TURBO_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 2) STD (Turbo UNet), no negatives (pure Turbo sample)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_plain = pipe_std_turbo(\n",
        "        prompt, guidance_scale=TURBO_CFG, generator=g, num_inference_steps=STEPS\n",
        "    ).images[0]\n",
        "\n",
        "    # 3) Impactful NAG with timed start and soft-start ramp\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_impactful_block = pipe_impactful_nag_turbo(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block_glasses,\n",
        "        nag_scale=NAG_SCALE,\n",
        "        nag_start=NAG_START,           # Enable NAG after NAG_START fraction of trajectory\n",
        "        nag_ramp_steps=NAG_RAMP_STEPS, # Optional soft-start ramp\n",
        "        nag_end=NAG_END,               # Keep NAG on until nag_end\n",
        "        guidance_scale=0.0,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    # 4) STD with normal negative_prompt (small CFG so it bites a little)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_block = pipe_std_turbo(\n",
        "        prompt,\n",
        "        negative_prompt=block_glasses,\n",
        "        guidance_scale=STD_BLOCKING_CFG,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_impactful_plain, img_std_plain, img_impactful_block, img_std_block])\n",
        "\n",
        "# ---------- Assemble comparison grid (4 rows × 4 cols) ----------\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new('RGB', (img_width * 4, img_height * 6))\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "print(\"Comparison Grid Layout (Impactful NAG; SDXL-Turbo, 4-step):\")\n",
        "print(\"Column 1: Impactful NAG (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: Impactful NAG + blocking     | Column 4: STD + blocking\")\n",
        "print(f\"  nag_start={NAG_START}, nag_ramp_steps={NAG_RAMP_STEPS}, nag_end={NAG_END}\")\n",
        "print(f\"Row 1: Seed {seeds[0]} | Row 2: Seed {seeds[1]} | Row 3: Seed {seeds[2]} | Row 4: Seed {seeds[3]}\")\n",
        "grid"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1761199334839
        }
      },
      "id": "843b68de-a843-484d-9847-765d0b1f754b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Impactful NAG (timed mid-window + DNG + attention-space normalisation)\n",
        "# Usage notes:\n",
        "#   - window=(0.15, 0.40) for noun/object negatives; try (0.30, 0.55) for adjective/style negatives\n",
        "#   - Auto-window only works if your NAG processor reports r_t; otherwise the static window is used\n",
        "#   - For few-step samplers (1–8), clamp dynamic phi in [3, 4], nag_tau≈2.5, nag_alpha≈0.25\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import (\n",
        "    UNet2DConditionModel,\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        ")\n",
        "\n",
        "# Add the workspace directory to sys.path (adjust if your project lives elsewhere)\n",
        "workspace_dir = \"/home/azureuser/cloudfiles/code/Users/Normalized-Attention-Guidance\"\n",
        "if workspace_dir not in sys.path:\n",
        "    sys.path.insert(0, workspace_dir)\n",
        "\n",
        "# Import the new Impactful pipeline implementation + DNG helpers\n",
        "from nag import (\n",
        "    ImpactfulNAGStableDiffusionXLPipeline,\n",
        "    DNGConfig,\n",
        "    make_dng_scale_fn,\n",
        ")\n",
        "\n",
        "# ---------- Config ----------\n",
        "device = \"cuda\"\n",
        "weights_dtype = torch.bfloat16\n",
        "basemodel_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "# Turbo UNet source (distilled SDXL UNet)\n",
        "turbo_repo = \"stabilityai/sdxl-turbo\"\n",
        "turbo_subfolder = \"unet\"\n",
        "\n",
        "# ---------- Base model (to borrow scheduler config cleanly) ----------\n",
        "_base = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, torch_dtype=weights_dtype, use_safetensors=True\n",
        ")\n",
        "base_sched_config = _base.scheduler.config\n",
        "del _base  # keep VRAM tidy\n",
        "\n",
        "# ---------- SDXL-Turbo distilled UNet ----------\n",
        "distilled_unet = UNet2DConditionModel.from_pretrained(\n",
        "    turbo_repo, subfolder=turbo_subfolder, torch_dtype=weights_dtype, variant=\"fp16\"\n",
        ").to(device, weights_dtype)\n",
        "\n",
        "# ---------- Pipelines (EulerA for Turbo, trailing timesteps) ----------\n",
        "pipe_nag_turbo = ImpactfulNAGStableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_nag_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ")\n",
        "\n",
        "pipe_std_turbo = StableDiffusionXLPipeline.from_pretrained(\n",
        "    basemodel_id, unet=distilled_unet, torch_dtype=weights_dtype, variant=\"fp16\", use_safetensors=True\n",
        ").to(device)\n",
        "pipe_std_turbo.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "    base_sched_config, timestep_spacing=\"trailing\"\n",
        ")\n",
        "\n",
        "# Build a clipped dynamic scale fn: DNG -> clamp to phi_max\n",
        "phi_max = 4.0\n",
        "base_dng = make_dng_scale_fn(DNGConfig(lambda0=5.0, p0=0.01, tau=0.25, eps=1e-3))\n",
        "def clipped_nag_scale_fn(*, step, total_steps, attn_stats):\n",
        "    val = base_dng(step=step, total_steps=total_steps, attn_stats=attn_stats)\n",
        "    return min(val, phi_max) if val is not None else None\n",
        "\n",
        "# ---------- Prompts, seeds, and settings ----------\n",
        "prompt = \"Hipster coffee shop worker\"\n",
        "block = \"glasses\"\n",
        "seeds = [2047, 2107, 2207, 2307, 2407, 2507]\n",
        "\n",
        "STEPS = 4               # SDXL-Turbo supports 1–4 steps; we keep 4 to match lightning-like comparisons\n",
        "TURBO_CFG = 0.0         # ADD-style sampling (CFG=0) for Turbo baseline\n",
        "\n",
        "STD_BLOCKING_CFG = 1.0  # small CFG so negative_prompt has some effect in the STD baseline\n",
        "\n",
        "rows = []\n",
        "for s in seeds:\n",
        "    # 1) Impactful NAG pipeline (Turbo UNet), no negatives\n",
        "    #    (NAG stays OFF here because we don't pass preset or nag_negative_prompt.)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_plain = pipe_nag_turbo(\n",
        "        prompt,\n",
        "        guidance_scale=TURBO_CFG,\n",
        "        generator=g,\n",
        "        num_inference_steps=STEPS,\n",
        "    ).images[0]\n",
        "\n",
        "    # 2) STD pipeline (Turbo UNet), no negatives (pure Turbo baseline)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_plain = pipe_std_turbo(\n",
        "        prompt,\n",
        "        guidance_scale=TURBO_CFG,\n",
        "        generator=g,\n",
        "        num_inference_steps=STEPS,\n",
        "    ).images[0]\n",
        "\n",
        "    # 3) Impactful NAG pipeline with blocking (timed mid-window + DNG + attention-space NAG)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_nag_block = pipe_nag_turbo(\n",
        "        prompt,\n",
        "        nag_negative_prompt=block,     # attention-space negative\n",
        "        guidance_scale=0.0,            # ADD-style; NAG handles suppression in attention space\n",
        "        generator=g,\n",
        "        num_inference_steps=STEPS,\n",
        "        preset=\"timed_dng_nag\",        # apply the recipe defaults (window, DNG, nag_scale, tau, alpha)\n",
        "        nag_scale_fn=clipped_nag_scale_fn,  # clamp dynamic phi to <= 4.0\n",
        "        # Optionally tweak the window:\n",
        "        # neg_window=(0.15, 0.40),     # noun/object negatives\n",
        "        # auto_neg_window=False,       # requires r_t from your NAG processor to be useful\n",
        "        # nag_tau=2.5, nag_alpha=0.25,\n",
        "    ).images[0]\n",
        "\n",
        "    # 4) STD pipeline with standard negative_prompt (output-space CFG path)\n",
        "    g = torch.Generator(device=device).manual_seed(s)\n",
        "    img_std_block = pipe_std_turbo(\n",
        "        prompt,\n",
        "        negative_prompt=block,\n",
        "        guidance_scale=STD_BLOCKING_CFG,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=g,\n",
        "    ).images[0]\n",
        "\n",
        "    rows.append([img_nag_plain, img_std_plain, img_nag_block, img_std_block])\n",
        "\n",
        "# ---------- Assemble comparison grid (6 rows × 4 cols) ----------\n",
        "img_height, img_width = rows[0][0].height, rows[0][0].width\n",
        "grid = Image.new(\"RGB\", (img_width * 4, img_height * len(rows)))\n",
        "for row_idx, row_images in enumerate(rows):\n",
        "    for col_idx, img in enumerate(row_images):\n",
        "        grid.paste(img, (col_idx * img_width, row_idx * img_height))\n",
        "\n",
        "print(\"Comparison Grid Layout (Impactful NAG; SDXL-Turbo, 4-step):\")\n",
        "print(\"Column 1: NAG pipeline (no negatives) | Column 2: STD (no negatives)\")\n",
        "print(\"Column 3: NAG pipeline + blocking     | Column 4: STD + blocking\")\n",
        "print(\"Rows (top to bottom): \" + \" | \".join(f\"Seed {s}\" for s in seeds))\n",
        "\n",
        "grid\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1761193243470
        }
      },
      "id": "72c19e57"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernel_info": {
      "name": "nag-venv"
    },
    "kernelspec": {
      "display_name": "NAG Virtual Environment",
      "language": "python",
      "name": "nag-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}